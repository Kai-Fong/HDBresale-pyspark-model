{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"table table-bordered\">\n",
    "    <tr>\n",
    "        <th style=\"width:250px\"><img src='https://www.np.edu.sg/images/default-source/default-album/img-logo.png?sfvrsn=764583a6_0' style=\"width: 100%; height: 125px; \"></th>\n",
    "        <th style=\"text-align:center;\"><h1>Distributed Data Pipelines</h1><h2>Assignment 1 </h2><h3>Diploma in Data Science</h3></th>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Objectives:\n",
    "- Design PySpark Based Machine Learning\n",
    "- Execute PySpark Syntax Correctly\n",
    "- Evaluate and Select Final Model based on Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be **graded on the use of PySpark**, so usage of **Pandas itself should be avoided as much as possible**, especially if a particular native method or function is already available in PySpark. **Penalties will be imposed in such cases.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the packages\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('6.1').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_25944\\1745900340.py:2: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# wider page width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- Step 1: [Problem Statement Formulation](#s1)\n",
    "    -  [Value Based Problem Statement](#ps)\n",
    "- Step 2: [Exploratory Data Analysis and Data Cleansing](#s2)\n",
    "- Step 3: [Data Wrangling and Transformation](#s3)\n",
    "- Step 4: [Machine Learning Modelling](#s4)\n",
    "- Step 5: [Model Evaluation and Selection](#s5)\n",
    "- Step 6: [Report](#rpt)\n",
    "- Presentation Video: [Video Presentation](#vid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Problem Statement Formulation <a name = \"s1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and explore data\n",
    "df_pyspark=spark.read.csv('./data/sg_flat_prices_mod.csv',\n",
    "                          header=True, inferSchema=True) # inferSchema auto detects data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- town: string (nullable = true)\n",
      " |-- flat_type: string (nullable = true)\n",
      " |-- block: string (nullable = true)\n",
      " |-- street_name: string (nullable = true)\n",
      " |-- storey_range: string (nullable = true)\n",
      " |-- floor_area_sqm: double (nullable = true)\n",
      " |-- flat_model: string (nullable = true)\n",
      " |-- lease_commence_date: integer (nullable = true)\n",
      " |-- remaining_lease: integer (nullable = true)\n",
      " |-- resale_price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View Dataset Schema\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+-----+-----------------+------------+--------------+--------------+-------------------+---------------+------------+\n",
      "|year|month|      town|flat_type|block|      street_name|storey_range|floor_area_sqm|    flat_model|lease_commence_date|remaining_lease|resale_price|\n",
      "+----+-----+----------+---------+-----+-----------------+------------+--------------+--------------+-------------------+---------------+------------+\n",
      "|2017|    1|ANG MO KIO|   2 ROOM|  406|ANG MO KIO AVE 10|    10 TO 12|          44.0|      Improved|               1979|            736|    232000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  108| ANG MO KIO AVE 4|    01 TO 03|          67.0|New Generation|               1978|            727|    250000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  602| ANG MO KIO AVE 5|    01 TO 03|          67.0|New Generation|               1980|            749|    262000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  465|ANG MO KIO AVE 10|    04 TO 06|          68.0|New Generation|               1980|            745|    265000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  601| ANG MO KIO AVE 5|    01 TO 03|          67.0|New Generation|               1980|            749|    265000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  150| ANG MO KIO AVE 5|    01 TO 03|          68.0|New Generation|               1981|            756|    275000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  447|ANG MO KIO AVE 10|    04 TO 06|          68.0|New Generation|               1979|            738|    280000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  218| ANG MO KIO AVE 1|    04 TO 06|          67.0|New Generation|               1976|            700|    285000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  447|ANG MO KIO AVE 10|    04 TO 06|          68.0|New Generation|               1979|            738|    285000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  571| ANG MO KIO AVE 3|    01 TO 03|          67.0|New Generation|               1979|            736|    285000.0|\n",
      "+----+-----+----------+---------+-----+-----------------+------------+--------------+--------------+-------------------+---------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View top 10 rows in dataset\n",
    "df_pyspark.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 64247\n",
      "Number of columns: 12\n",
      "Shape of the Dataframe: (64247, 12)\n"
     ]
    }
   ],
   "source": [
    "# Dimension of Dataframe\n",
    "row = df_pyspark.count()\n",
    "col = len(df_pyspark.columns)\n",
    " \n",
    "# display\n",
    "print(f'Number of rows: {row}')\n",
    "print(f'Number of columns: {col}')\n",
    "print(f'Shape of the Dataframe: {(row,col)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+----------+----------------+------------------+------------+\n",
      "|summary|              year|             month|      town|       flat_type|             block| street_name|\n",
      "+-------+------------------+------------------+----------+----------------+------------------+------------+\n",
      "|  count|             64247|             64247|     64247|           64247|             64247|       64247|\n",
      "|   mean|2018.0262424704656| 6.779133656046197|      null|            null| 349.4635640052788|        null|\n",
      "| stddev|0.8146939469668695|3.2635673352950514|      null|            null|254.80560486394563|        null|\n",
      "|    min|              2017|                 1|ANG MO KIO|          1 ROOM|                 1|ADMIRALTY DR|\n",
      "|    max|              2019|                12|    YISHUN|MULTI-GENERATION|                9B|     ZION RD|\n",
      "+-------+------------------+------------------+----------+----------------+------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Summary of first 6 columns\n",
    "df_pyspark.describe(['year','month','town','flat_type','block','street_name']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+-----------------+-------------+-------------------+------------------+------------------+\n",
      "|summary|storey_range|   floor_area_sqm|   flat_model|lease_commence_date|   remaining_lease|      resale_price|\n",
      "+-------+------------+-----------------+-------------+-------------------+------------------+------------------+\n",
      "|  count|       64247|            64197|        64247|              64247|             64247|             64247|\n",
      "|   mean|        null|97.77009984890256|         null| 1993.6012420813422| 894.6413840334957|438943.70469516085|\n",
      "| stddev|        null|24.26994610142912|         null| 12.465629502278013|149.62669792791093|153760.65294972394|\n",
      "|    min|    01 TO 03|             31.0|Adjoined flat|               1966|               553|          150000.0|\n",
      "|    max|    49 TO 51|            249.0|      Type S2|               2016|              1160|         1205000.0|\n",
      "+-------+------------+-----------------+-------------+-------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Summary of next 6 columns\n",
    "df_pyspark.describe(['storey_range','floor_area_sqm','flat_model','lease_commence_date','remaining_lease','resale_price']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(storey_range='43 TO 45'),\n",
       " Row(storey_range='37 TO 39'),\n",
       " Row(storey_range='10 TO 12'),\n",
       " Row(storey_range='04 TO 06'),\n",
       " Row(storey_range='40 TO 42'),\n",
       " Row(storey_range='16 TO 18'),\n",
       " Row(storey_range='19 TO 21'),\n",
       " Row(storey_range='34 TO 36'),\n",
       " Row(storey_range='31 TO 33'),\n",
       " Row(storey_range='13 TO 15'),\n",
       " Row(storey_range='46 TO 48'),\n",
       " Row(storey_range='22 TO 24'),\n",
       " Row(storey_range='25 TO 27'),\n",
       " Row(storey_range='07 TO 09'),\n",
       " Row(storey_range='01 TO 03'),\n",
       " Row(storey_range='28 TO 30'),\n",
       " Row(storey_range='49 TO 51')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show unique values for categorical features (limit to 30) (storey_range, town, flat_model, flat_type, street_name)\n",
    "# storey_range\n",
    "df_pyspark.select('storey_range').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(town='QUEENSTOWN'),\n",
       " Row(town='BEDOK'),\n",
       " Row(town='CLEMENTI'),\n",
       " Row(town='SERANGOON'),\n",
       " Row(town='BUKIT PANJANG'),\n",
       " Row(town='BUKIT TIMAH'),\n",
       " Row(town='YISHUN'),\n",
       " Row(town='GEYLANG'),\n",
       " Row(town='WOODLANDS'),\n",
       " Row(town='BUKIT MERAH'),\n",
       " Row(town='TOA PAYOH'),\n",
       " Row(town='BISHAN'),\n",
       " Row(town='PUNGGOL'),\n",
       " Row(town='HOUGANG'),\n",
       " Row(town='ANG MO KIO'),\n",
       " Row(town='PASIR RIS'),\n",
       " Row(town='SENGKANG'),\n",
       " Row(town='KALLANG/WHAMPOA'),\n",
       " Row(town='BUKIT BATOK'),\n",
       " Row(town='TAMPINES'),\n",
       " Row(town='JURONG WEST'),\n",
       " Row(town='JURONG EAST'),\n",
       " Row(town='MARINE PARADE'),\n",
       " Row(town='CENTRAL AREA'),\n",
       " Row(town='SEMBAWANG'),\n",
       " Row(town='CHOA CHU KANG')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# town\n",
    "df_pyspark.select('town').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(flat_model='Apartment'),\n",
       " Row(flat_model='Premium Maisonette'),\n",
       " Row(flat_model='Improved'),\n",
       " Row(flat_model='Type S2'),\n",
       " Row(flat_model='New Generation'),\n",
       " Row(flat_model='Improved-Maisonette'),\n",
       " Row(flat_model='Model A-Maisonette'),\n",
       " Row(flat_model='Maisonette'),\n",
       " Row(flat_model='Multi Generation'),\n",
       " Row(flat_model='Model A'),\n",
       " Row(flat_model='DBSS'),\n",
       " Row(flat_model='Simplified'),\n",
       " Row(flat_model='Terrace'),\n",
       " Row(flat_model='Adjoined flat'),\n",
       " Row(flat_model='Type S1'),\n",
       " Row(flat_model='Standard'),\n",
       " Row(flat_model='Premium Apartment'),\n",
       " Row(flat_model='Model A2'),\n",
       " Row(flat_model='Premium Apartment Loft')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flat model\n",
    "df_pyspark.select('flat_model').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(flat_type='3 ROOM'),\n",
       " Row(flat_type='1 ROOM'),\n",
       " Row(flat_type='4 ROOM'),\n",
       " Row(flat_type='2 ROOM'),\n",
       " Row(flat_type='EXECUTIVE'),\n",
       " Row(flat_type='5 ROOM'),\n",
       " Row(flat_type='MULTI-GENERATION')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flat type\n",
    "df_pyspark.select('flat_type').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(street_name='BEDOK STH AVE 3'),\n",
       " Row(street_name='JURONG EAST ST 32'),\n",
       " Row(street_name='NTH BRIDGE RD'),\n",
       " Row(street_name='BEDOK NTH ST 2'),\n",
       " Row(street_name='CRAWFORD LANE'),\n",
       " Row(street_name='ANG MO KIO ST 21'),\n",
       " Row(street_name='SEMBAWANG CRES'),\n",
       " Row(street_name='RIVERVALE DR'),\n",
       " Row(street_name='WOODLANDS DR 60'),\n",
       " Row(street_name='LIM LIAK ST'),\n",
       " Row(street_name='BEDOK NTH AVE 3'),\n",
       " Row(street_name='CHOA CHU KANG NTH 6'),\n",
       " Row(street_name='LOR 8 TOA PAYOH'),\n",
       " Row(street_name='JOO SENG RD'),\n",
       " Row(street_name='TAO CHING RD'),\n",
       " Row(street_name='CHOA CHU KANG ST 53'),\n",
       " Row(street_name='PUNGGOL PL'),\n",
       " Row(street_name='JLN DAMAI'),\n",
       " Row(street_name='MCNAIR RD'),\n",
       " Row(street_name='EVERTON PK'),\n",
       " Row(street_name='BT BATOK ST 25'),\n",
       " Row(street_name='JLN BT HO SWEE'),\n",
       " Row(street_name='KALLANG BAHRU'),\n",
       " Row(street_name='YISHUN ST 20'),\n",
       " Row(street_name='BEDOK NTH ST 4'),\n",
       " Row(street_name='SERANGOON NTH AVE 3'),\n",
       " Row(street_name='ANG MO KIO AVE 8'),\n",
       " Row(street_name='QUEEN ST'),\n",
       " Row(street_name=\"ST. GEORGE'S RD\"),\n",
       " Row(street_name='YISHUN ST 61'),\n",
       " Row(street_name='BUFFALO RD'),\n",
       " Row(street_name='ANCHORVALE CRES'),\n",
       " Row(street_name='BT BATOK ST 31'),\n",
       " Row(street_name='JURONG WEST ST 71'),\n",
       " Row(street_name='KLANG LANE'),\n",
       " Row(street_name='BOON KENG RD'),\n",
       " Row(street_name='JURONG EAST ST 31'),\n",
       " Row(street_name='ANG MO KIO AVE 9'),\n",
       " Row(street_name='EDGEFIELD PLAINS'),\n",
       " Row(street_name='JELAPANG RD'),\n",
       " Row(street_name='PASIR RIS ST 51'),\n",
       " Row(street_name='PUNGGOL WALK'),\n",
       " Row(street_name='ANG MO KIO AVE 4'),\n",
       " Row(street_name='BEDOK STH AVE 1'),\n",
       " Row(street_name='OLD AIRPORT RD'),\n",
       " Row(street_name='PUNGGOL DR'),\n",
       " Row(street_name='SPOTTISWOODE PK RD'),\n",
       " Row(street_name='JURONG WEST ST 91'),\n",
       " Row(street_name='PASIR RIS ST 72'),\n",
       " Row(street_name='WOODLANDS DR 62'),\n",
       " Row(street_name='YISHUN AVE 4'),\n",
       " Row(street_name='HOUGANG ST 22'),\n",
       " Row(street_name='ANCHORVALE ST'),\n",
       " Row(street_name='JLN RUMAH TINGGI'),\n",
       " Row(street_name='JLN MEMBINA'),\n",
       " Row(street_name=\"QUEEN'S RD\"),\n",
       " Row(street_name='BEDOK STH AVE 2'),\n",
       " Row(street_name='SENJA LINK'),\n",
       " Row(street_name='JURONG EAST ST 13'),\n",
       " Row(street_name='UPP SERANGOON CRES'),\n",
       " Row(street_name='ELIAS RD'),\n",
       " Row(street_name='ANG MO KIO ST 31'),\n",
       " Row(street_name='SEGAR RD'),\n",
       " Row(street_name='ROWELL RD'),\n",
       " Row(street_name='GEYLANG EAST AVE 1'),\n",
       " Row(street_name='JURONG EAST ST 21'),\n",
       " Row(street_name='WOODLANDS CRES'),\n",
       " Row(street_name='MONTREAL DR'),\n",
       " Row(street_name='DOVER CL EAST'),\n",
       " Row(street_name='UPP SERANGOON RD'),\n",
       " Row(street_name='YUNG SHENG RD'),\n",
       " Row(street_name='JLN KAYU'),\n",
       " Row(street_name='WOODLANDS AVE 6'),\n",
       " Row(street_name='LOR LEW LIAN'),\n",
       " Row(street_name='YISHUN ST 41'),\n",
       " Row(street_name='HOUGANG AVE 7'),\n",
       " Row(street_name='SIMEI ST 1'),\n",
       " Row(street_name='SIMEI ST 5'),\n",
       " Row(street_name='JOO CHIAT RD'),\n",
       " Row(street_name='HOUGANG AVE 6'),\n",
       " Row(street_name='PASIR RIS ST 12'),\n",
       " Row(street_name='WOODLANDS DR 50'),\n",
       " Row(street_name='JLN TENAGA'),\n",
       " Row(street_name='CLEMENTI ST 12'),\n",
       " Row(street_name=\"C'WEALTH DR\"),\n",
       " Row(street_name='CLARENCE LANE'),\n",
       " Row(street_name='GEYLANG SERAI'),\n",
       " Row(street_name='MONTREAL LINK'),\n",
       " Row(street_name='HOUGANG ST 52'),\n",
       " Row(street_name='CLEMENTI ST 11'),\n",
       " Row(street_name='JURONG WEST ST 93'),\n",
       " Row(street_name='OWEN RD'),\n",
       " Row(street_name='YISHUN ST 81'),\n",
       " Row(street_name='JURONG WEST ST 81'),\n",
       " Row(street_name='TAMPINES ST 41'),\n",
       " Row(street_name='YISHUN AVE 2'),\n",
       " Row(street_name='COMPASSVALE DR'),\n",
       " Row(street_name='WOODLANDS DR 52'),\n",
       " Row(street_name='TAMAN HO SWEE'),\n",
       " Row(street_name='SERANGOON CTRL'),\n",
       " Row(street_name='TAMPINES ST 83'),\n",
       " Row(street_name='UPP ALJUNIED LANE'),\n",
       " Row(street_name='JLN TENTERAM'),\n",
       " Row(street_name='STRATHMORE AVE'),\n",
       " Row(street_name='WOODLANDS AVE 4'),\n",
       " Row(street_name='CLEMENTI ST 14'),\n",
       " Row(street_name='CHAI CHEE AVE'),\n",
       " Row(street_name='JURONG WEST ST 42'),\n",
       " Row(street_name='WOODLANDS DR 71'),\n",
       " Row(street_name='CHOA CHU KANG CRES'),\n",
       " Row(street_name='CHANGI VILLAGE RD'),\n",
       " Row(street_name='ANCHORVALE LINK'),\n",
       " Row(street_name='BEDOK RESERVOIR RD'),\n",
       " Row(street_name='WOODLANDS DR 72'),\n",
       " Row(street_name='SENGKANG EAST AVE'),\n",
       " Row(street_name='INDUS RD'),\n",
       " Row(street_name='SENJA RD'),\n",
       " Row(street_name='SERANGOON AVE 2'),\n",
       " Row(street_name='CHOA CHU KANG LOOP'),\n",
       " Row(street_name='CLEMENTI AVE 1'),\n",
       " Row(street_name='BUANGKOK LINK'),\n",
       " Row(street_name='TAMPINES ST 71'),\n",
       " Row(street_name='WOODLANDS CIRCLE'),\n",
       " Row(street_name='WOODLANDS AVE 1'),\n",
       " Row(street_name='KRETA AYER RD'),\n",
       " Row(street_name='CHOA CHU KANG AVE 2'),\n",
       " Row(street_name=\"C'WEALTH CL\"),\n",
       " Row(street_name='YISHUN RING RD'),\n",
       " Row(street_name='KIM TIAN RD'),\n",
       " Row(street_name='CHAI CHEE RD'),\n",
       " Row(street_name='JLN TIGA'),\n",
       " Row(street_name='TAMPINES CTRL 8'),\n",
       " Row(street_name='BEDOK RESERVOIR CRES'),\n",
       " Row(street_name='FARRER RD'),\n",
       " Row(street_name='KG ARANG RD'),\n",
       " Row(street_name='BOON LAY AVE'),\n",
       " Row(street_name='PASIR RIS ST 71'),\n",
       " Row(street_name='DAKOTA CRES'),\n",
       " Row(street_name='ANG MO KIO AVE 1'),\n",
       " Row(street_name='HOUGANG AVE 8'),\n",
       " Row(street_name='JURONG WEST ST 62'),\n",
       " Row(street_name='PASIR RIS ST 52'),\n",
       " Row(street_name='UPP CROSS ST'),\n",
       " Row(street_name='BT BATOK WEST AVE 2'),\n",
       " Row(street_name='WOODLANDS AVE 9'),\n",
       " Row(street_name='CHOA CHU KANG DR'),\n",
       " Row(street_name='FERNVALE LANE'),\n",
       " Row(street_name='JURONG WEST ST 51'),\n",
       " Row(street_name='CHOA CHU KANG NTH 5'),\n",
       " Row(street_name='HOUGANG AVE 5'),\n",
       " Row(street_name='MARSILING RISE'),\n",
       " Row(street_name=\"C'WEALTH AVE WEST\"),\n",
       " Row(street_name='SERANGOON NTH AVE 4'),\n",
       " Row(street_name='TAMPINES ST 24'),\n",
       " Row(street_name='BT BATOK ST 32'),\n",
       " Row(street_name='BT BATOK CTRL'),\n",
       " Row(street_name='TELOK BLANGAH DR'),\n",
       " Row(street_name='DEPOT RD'),\n",
       " Row(street_name='WOODLANDS ST 32'),\n",
       " Row(street_name='BT MERAH VIEW'),\n",
       " Row(street_name='JURONG EAST ST 24'),\n",
       " Row(street_name='PUNGGOL RD'),\n",
       " Row(street_name='WOODLANDS RING RD'),\n",
       " Row(street_name='YISHUN ST 21'),\n",
       " Row(street_name='KANG CHING RD'),\n",
       " Row(street_name='PASIR RIS DR 6'),\n",
       " Row(street_name='PASIR RIS DR 4'),\n",
       " Row(street_name='WOODLANDS DR 53'),\n",
       " Row(street_name='TECK WHYE AVE'),\n",
       " Row(street_name='BT BATOK ST 52'),\n",
       " Row(street_name='HAVELOCK RD'),\n",
       " Row(street_name='HAIG RD'),\n",
       " Row(street_name='WOODLANDS DR 70'),\n",
       " Row(street_name='WOODLANDS DR 14'),\n",
       " Row(street_name='YISHUN AVE 6'),\n",
       " Row(street_name='PASIR RIS ST 13'),\n",
       " Row(street_name='KIM CHENG ST'),\n",
       " Row(street_name='CHOA CHU KANG NTH 7'),\n",
       " Row(street_name='BAIN ST'),\n",
       " Row(street_name='TAMPINES ST 91'),\n",
       " Row(street_name='SMITH ST'),\n",
       " Row(street_name='HOUGANG ST 92'),\n",
       " Row(street_name='PAYA LEBAR WAY'),\n",
       " Row(street_name='SERANGOON NTH AVE 2'),\n",
       " Row(street_name='PASIR RIS ST 41'),\n",
       " Row(street_name='LOR 1A TOA PAYOH'),\n",
       " Row(street_name='CHOA CHU KANG AVE 3'),\n",
       " Row(street_name='HOUGANG ST 91'),\n",
       " Row(street_name='SILAT AVE'),\n",
       " Row(street_name='CHAI CHEE ST'),\n",
       " Row(street_name='YISHUN CTRL'),\n",
       " Row(street_name='MACPHERSON LANE'),\n",
       " Row(street_name='HOUGANG ST 31'),\n",
       " Row(street_name='ALJUNIED RD'),\n",
       " Row(street_name='JLN DUA'),\n",
       " Row(street_name='JURONG WEST ST 65'),\n",
       " Row(street_name='LOR 5 TOA PAYOH'),\n",
       " Row(street_name='ANCHORVALE DR'),\n",
       " Row(street_name='HOUGANG AVE 3'),\n",
       " Row(street_name='BOON LAY DR'),\n",
       " Row(street_name='CHANDER RD'),\n",
       " Row(street_name='CLEMENTI WEST ST 2'),\n",
       " Row(street_name='TAH CHING RD'),\n",
       " Row(street_name='ANG MO KIO ST 32'),\n",
       " Row(street_name='VEERASAMY RD'),\n",
       " Row(street_name='TAMPINES ST 11'),\n",
       " Row(street_name='TAMPINES ST 21'),\n",
       " Row(street_name='WOODLANDS DR 75'),\n",
       " Row(street_name='AH HOOD RD'),\n",
       " Row(street_name='HOUGANG AVE 1'),\n",
       " Row(street_name='EDGEDALE PLAINS'),\n",
       " Row(street_name='WOODLANDS ST 13'),\n",
       " Row(street_name='BEACH RD'),\n",
       " Row(street_name='ANG MO KIO AVE 3'),\n",
       " Row(street_name='BEDOK STH RD'),\n",
       " Row(street_name='TELOK BLANGAH HTS'),\n",
       " Row(street_name='CHOA CHU KANG ST 52'),\n",
       " Row(street_name='ANCHORVALE RD'),\n",
       " Row(street_name='HOY FATT RD'),\n",
       " Row(street_name='YISHUN ST 31'),\n",
       " Row(street_name='YUNG HO RD'),\n",
       " Row(street_name='LOR LIMAU'),\n",
       " Row(street_name='CLEMENTI ST 13'),\n",
       " Row(street_name='LOR 3 GEYLANG'),\n",
       " Row(street_name='HOUGANG ST 51'),\n",
       " Row(street_name='GEYLANG BAHRU'),\n",
       " Row(street_name='MARSILING LANE'),\n",
       " Row(street_name='BT BATOK WEST AVE 7'),\n",
       " Row(street_name='CHOA CHU KANG ST 64'),\n",
       " Row(street_name='JURONG WEST CTRL 1'),\n",
       " Row(street_name='TOA PAYOH CTRL'),\n",
       " Row(street_name='SEMBAWANG VISTA'),\n",
       " Row(street_name='LOWER DELTA RD'),\n",
       " Row(street_name='BEDOK NTH ST 3'),\n",
       " Row(street_name='BRIGHT HILL DR'),\n",
       " Row(street_name='MOH GUAN TER'),\n",
       " Row(street_name='SENGKANG WEST AVE'),\n",
       " Row(street_name='HO CHING RD'),\n",
       " Row(street_name='HOUGANG ST 21'),\n",
       " Row(street_name='MARSILING RD'),\n",
       " Row(street_name='BEDOK NTH AVE 4'),\n",
       " Row(street_name='CHOA CHU KANG ST 54'),\n",
       " Row(street_name='TAMPINES AVE 8'),\n",
       " Row(street_name='DELTA AVE'),\n",
       " Row(street_name='CHOA CHU KANG AVE 4'),\n",
       " Row(street_name='SEMBAWANG DR'),\n",
       " Row(street_name='SERANGOON AVE 4'),\n",
       " Row(street_name='TAMPINES ST 84'),\n",
       " Row(street_name='REDHILL CL'),\n",
       " Row(street_name=\"QUEEN'S CL\"),\n",
       " Row(street_name='DOVER RD'),\n",
       " Row(street_name='MARSILING DR'),\n",
       " Row(street_name='YISHUN ST 72'),\n",
       " Row(street_name='KIM KEAT LINK'),\n",
       " Row(street_name='SIN MING RD'),\n",
       " Row(street_name='PENDING RD'),\n",
       " Row(street_name='PASIR RIS DR 1'),\n",
       " Row(street_name='BEDOK NTH ST 1'),\n",
       " Row(street_name='ANG MO KIO ST 52'),\n",
       " Row(street_name='JURONG WEST ST 64'),\n",
       " Row(street_name=\"ST. GEORGE'S LANE\"),\n",
       " Row(street_name='YUNG AN RD'),\n",
       " Row(street_name='BT BATOK ST 11'),\n",
       " Row(street_name='FARRER PK RD'),\n",
       " Row(street_name='WHAMPOA WEST'),\n",
       " Row(street_name='PUNGGOL WAY'),\n",
       " Row(street_name='BISHAN ST 13'),\n",
       " Row(street_name='HOUGANG AVE 10'),\n",
       " Row(street_name='HOLLAND CL'),\n",
       " Row(street_name='SERANGOON CTRL DR'),\n",
       " Row(street_name='YISHUN AVE 9'),\n",
       " Row(street_name='BISHAN ST 23'),\n",
       " Row(street_name='TOWNER RD'),\n",
       " Row(street_name='SIN MING AVE'),\n",
       " Row(street_name='SHUNFU RD'),\n",
       " Row(street_name='PIPIT RD'),\n",
       " Row(street_name=\"C'WEALTH CRES\"),\n",
       " Row(street_name='SIMEI LANE'),\n",
       " Row(street_name='TIONG BAHRU RD'),\n",
       " Row(street_name='FERNVALE LINK'),\n",
       " Row(street_name='ANG MO KIO ST 61'),\n",
       " Row(street_name='ANG MO KIO AVE 10'),\n",
       " Row(street_name='TELOK BLANGAH WAY'),\n",
       " Row(street_name='CLEMENTI AVE 2'),\n",
       " Row(street_name='JURONG WEST ST 52'),\n",
       " Row(street_name='PASIR RIS ST 21'),\n",
       " Row(street_name='CANBERRA RD'),\n",
       " Row(street_name='YISHUN AVE 11'),\n",
       " Row(street_name='TESSENSOHN RD'),\n",
       " Row(street_name='BISHAN ST 12'),\n",
       " Row(street_name='JLN KLINIK'),\n",
       " Row(street_name='COMPASSVALE BOW'),\n",
       " Row(street_name='TOA PAYOH EAST'),\n",
       " Row(street_name='JURONG WEST ST 75'),\n",
       " Row(street_name='CLEMENTI AVE 6'),\n",
       " Row(street_name='YUAN CHING RD'),\n",
       " Row(street_name='ANG MO KIO AVE 6'),\n",
       " Row(street_name='JLN BATU'),\n",
       " Row(street_name='SENGKANG CTRL'),\n",
       " Row(street_name='BT BATOK ST 21'),\n",
       " Row(street_name='BT MERAH LANE 1'),\n",
       " Row(street_name='WOODLANDS DR 44'),\n",
       " Row(street_name='RIVERVALE WALK'),\n",
       " Row(street_name='YUNG PING RD'),\n",
       " Row(street_name='CHOA CHU KANG ST 62'),\n",
       " Row(street_name='SELEGIE RD'),\n",
       " Row(street_name='JLN TECK WHYE'),\n",
       " Row(street_name='CHOA CHU KANG AVE 5'),\n",
       " Row(street_name='TELOK BLANGAH ST 31'),\n",
       " Row(street_name='HOUGANG AVE 2'),\n",
       " Row(street_name='MEI LING ST'),\n",
       " Row(street_name='POTONG PASIR AVE 1'),\n",
       " Row(street_name='BEDOK NTH AVE 1'),\n",
       " Row(street_name='LOR 2 TOA PAYOH'),\n",
       " Row(street_name='STIRLING RD'),\n",
       " Row(street_name='LOR 1 TOA PAYOH'),\n",
       " Row(street_name='TOA PAYOH NTH'),\n",
       " Row(street_name='CANTONMENT RD'),\n",
       " Row(street_name='RIVERVALE ST'),\n",
       " Row(street_name='WOODLANDS ST 31'),\n",
       " Row(street_name='YISHUN ST 11'),\n",
       " Row(street_name='TAMPINES ST 81'),\n",
       " Row(street_name='BEDOK NTH AVE 2'),\n",
       " Row(street_name='DORSET RD'),\n",
       " Row(street_name='CHIN SWEE RD'),\n",
       " Row(street_name='YISHUN ST 51'),\n",
       " Row(street_name='TOH YI DR'),\n",
       " Row(street_name='NEW MKT RD'),\n",
       " Row(street_name='BT BATOK EAST AVE 5'),\n",
       " Row(street_name='TAMPINES ST 72'),\n",
       " Row(street_name='TAMPINES ST 12'),\n",
       " Row(street_name='YUNG LOH RD'),\n",
       " Row(street_name='JLN BT MERAH'),\n",
       " Row(street_name='TECK WHYE CRES'),\n",
       " Row(street_name='SUMANG LINK'),\n",
       " Row(street_name='TEBAN GDNS RD'),\n",
       " Row(street_name='JURONG WEST ST 61'),\n",
       " Row(street_name='SERANGOON AVE 1'),\n",
       " Row(street_name='KELANTAN RD'),\n",
       " Row(street_name='SEMBAWANG WAY'),\n",
       " Row(street_name='CHAI CHEE DR'),\n",
       " Row(street_name='BT BATOK EAST AVE 3'),\n",
       " Row(street_name='CHOA CHU KANG ST 51'),\n",
       " Row(street_name='SENGKANG EAST RD'),\n",
       " Row(street_name='JELEBU RD'),\n",
       " Row(street_name='ALJUNIED CRES'),\n",
       " Row(street_name='TELOK BLANGAH RISE'),\n",
       " Row(street_name='HOUGANG ST 11'),\n",
       " Row(street_name='TAMPINES AVE 7'),\n",
       " Row(street_name='CLEMENTI AVE 3'),\n",
       " Row(street_name='MARINE CRES'),\n",
       " Row(street_name='LOR AH SOO'),\n",
       " Row(street_name='CANTONMENT CL'),\n",
       " Row(street_name='WOODLANDS ST 11'),\n",
       " Row(street_name='TAMPINES CTRL 1'),\n",
       " Row(street_name='WOODLANDS DR 73'),\n",
       " Row(street_name='LENGKONG TIGA'),\n",
       " Row(street_name='TAMPINES CTRL 7'),\n",
       " Row(street_name='YISHUN AVE 3'),\n",
       " Row(street_name='WEST COAST DR'),\n",
       " Row(street_name=\"C'WEALTH AVE\"),\n",
       " Row(street_name='BT BATOK ST 24'),\n",
       " Row(street_name='JURONG WEST ST 72'),\n",
       " Row(street_name='BT BATOK ST 51'),\n",
       " Row(street_name='EUNOS RD 5'),\n",
       " Row(street_name='PASIR RIS DR 3'),\n",
       " Row(street_name='TAMPINES ST 45'),\n",
       " Row(street_name='CAMBRIDGE RD'),\n",
       " Row(street_name='ANG MO KIO ST 11'),\n",
       " Row(street_name='SEMBAWANG CL'),\n",
       " Row(street_name='COMPASSVALE ST'),\n",
       " Row(street_name='YISHUN ST 22'),\n",
       " Row(street_name='CASHEW RD'),\n",
       " Row(street_name='CASSIA CRES'),\n",
       " Row(street_name='JURONG WEST ST 73'),\n",
       " Row(street_name='YISHUN ST 71'),\n",
       " Row(street_name='UPP SERANGOON VIEW'),\n",
       " Row(street_name='BT BATOK WEST AVE 6'),\n",
       " Row(street_name='CIRCUIT RD'),\n",
       " Row(street_name='TAMPINES ST 32'),\n",
       " Row(street_name='BT BATOK ST 33'),\n",
       " Row(street_name='CHOA CHU KANG CTRL'),\n",
       " Row(street_name='MARSILING CRES'),\n",
       " Row(street_name='WOODLANDS DR 16'),\n",
       " Row(street_name='GHIM MOH LINK'),\n",
       " Row(street_name='TAMPINES AVE 1'),\n",
       " Row(street_name='NEW UPP CHANGI RD'),\n",
       " Row(street_name='BT BATOK ST 22'),\n",
       " Row(street_name='ANCHORVALE LANE'),\n",
       " Row(street_name='POTONG PASIR AVE 3'),\n",
       " Row(street_name='WHAMPOA RD'),\n",
       " Row(street_name='SIMS PL'),\n",
       " Row(street_name='WOODLANDS ST 81'),\n",
       " Row(street_name='KIM TIAN PL'),\n",
       " Row(street_name='SIMS DR'),\n",
       " Row(street_name='TAMPINES AVE 4'),\n",
       " Row(street_name='GLOUCESTER RD'),\n",
       " Row(street_name='FRENCH RD'),\n",
       " Row(street_name='BALAM RD'),\n",
       " Row(street_name='JLN BAHAGIA'),\n",
       " Row(street_name='KG KAYU RD'),\n",
       " Row(street_name='MARINE TER'),\n",
       " Row(street_name='ANG MO KIO AVE 2'),\n",
       " Row(street_name='BANGKIT RD'),\n",
       " Row(street_name='BUANGKOK CRES'),\n",
       " Row(street_name='PASIR RIS ST 11'),\n",
       " Row(street_name='COMPASSVALE LINK'),\n",
       " Row(street_name='TAMPINES ST 82'),\n",
       " Row(street_name='WHAMPOA STH'),\n",
       " Row(street_name='TAMPINES ST 34'),\n",
       " Row(street_name='JLN BERSEH'),\n",
       " Row(street_name='CLEMENTI AVE 5'),\n",
       " Row(street_name='SAUJANA RD'),\n",
       " Row(street_name='BEDOK RESERVOIR VIEW'),\n",
       " Row(street_name='SERANGOON AVE 3'),\n",
       " Row(street_name='KIM PONG RD'),\n",
       " Row(street_name='RACE COURSE RD'),\n",
       " Row(street_name='PASIR RIS DR 10'),\n",
       " Row(street_name='TANGLIN HALT RD'),\n",
       " Row(street_name='WOODLANDS AVE 3'),\n",
       " Row(street_name='BISHAN ST 11'),\n",
       " Row(street_name='JURONG WEST AVE 3'),\n",
       " Row(street_name='LOR 4 TOA PAYOH'),\n",
       " Row(street_name='CLEMENTI AVE 4'),\n",
       " Row(street_name='TAMPINES ST 23'),\n",
       " Row(street_name='SENGKANG WEST WAY'),\n",
       " Row(street_name='BISHAN ST 24'),\n",
       " Row(street_name='BT BATOK WEST AVE 5'),\n",
       " Row(street_name='REDHILL RD'),\n",
       " Row(street_name='BT PANJANG RING RD'),\n",
       " Row(street_name='LOR 6 TOA PAYOH'),\n",
       " Row(street_name='CORPORATION DR'),\n",
       " Row(street_name='BEDOK NTH RD'),\n",
       " Row(street_name='BEDOK CTRL'),\n",
       " Row(street_name='BOON LAY PL'),\n",
       " Row(street_name='FAJAR RD'),\n",
       " Row(street_name='GEYLANG EAST CTRL'),\n",
       " Row(street_name=\"JLN MA'MOR\"),\n",
       " Row(street_name='CLEMENTI WEST ST 1'),\n",
       " Row(street_name='CANBERRA LINK'),\n",
       " Row(street_name='LENGKOK BAHRU'),\n",
       " Row(street_name='JLN KUKOH'),\n",
       " Row(street_name='TAMPINES ST 44'),\n",
       " Row(street_name='JURONG WEST ST 24'),\n",
       " Row(street_name='UPP BOON KENG RD'),\n",
       " Row(street_name='ADMIRALTY LINK'),\n",
       " Row(street_name='COMPASSVALE WALK'),\n",
       " Row(street_name='BEO CRES'),\n",
       " Row(street_name='COMPASSVALE LANE'),\n",
       " Row(street_name='WOODLANDS ST 82'),\n",
       " Row(street_name='KIM KEAT AVE'),\n",
       " Row(street_name='BT BATOK EAST AVE 4'),\n",
       " Row(street_name='JURONG EAST AVE 1'),\n",
       " Row(street_name='SENGKANG EAST WAY'),\n",
       " Row(street_name='SIMEI ST 4'),\n",
       " Row(street_name='PUNGGOL FIELD'),\n",
       " Row(street_name='WOODLANDS ST 83'),\n",
       " Row(street_name='CHOA CHU KANG AVE 1'),\n",
       " Row(street_name='JELLICOE RD'),\n",
       " Row(street_name='BISHAN ST 22'),\n",
       " Row(street_name='WHAMPOA DR'),\n",
       " Row(street_name='LOR 3 TOA PAYOH'),\n",
       " Row(street_name='WOODLANDS DR 40'),\n",
       " Row(street_name='HOUGANG CTRL'),\n",
       " Row(street_name='GHIM MOH RD'),\n",
       " Row(street_name='SIMEI ST 2'),\n",
       " Row(street_name='TAMPINES ST 43'),\n",
       " Row(street_name='TECK WHYE LANE'),\n",
       " Row(street_name='TAMPINES AVE 9'),\n",
       " Row(street_name='SIMEI RD'),\n",
       " Row(street_name='MARINE DR'),\n",
       " Row(street_name='PASIR RIS ST 53'),\n",
       " Row(street_name='HOLLAND AVE'),\n",
       " Row(street_name='POTONG PASIR AVE 2'),\n",
       " Row(street_name='BT PURMEI RD'),\n",
       " Row(street_name='ZION RD'),\n",
       " Row(street_name='EUNOS CRES'),\n",
       " Row(street_name='PUNGGOL EAST'),\n",
       " Row(street_name='YISHUN AVE 1'),\n",
       " Row(street_name='TELOK BLANGAH CRES'),\n",
       " Row(street_name='UBI AVE 1'),\n",
       " Row(street_name='PUNGGOL FIELD WALK'),\n",
       " Row(street_name='HOLLAND DR'),\n",
       " Row(street_name='WOODLANDS DR 42'),\n",
       " Row(street_name='YISHUN AVE 5'),\n",
       " Row(street_name='TAMPINES ST 42'),\n",
       " Row(street_name='EMPRESS RD'),\n",
       " Row(street_name='BT BATOK ST 34'),\n",
       " Row(street_name='WATERLOO ST'),\n",
       " Row(street_name='TAMPINES AVE 5'),\n",
       " Row(street_name='BOON TIONG RD'),\n",
       " Row(street_name='JLN DUSUN'),\n",
       " Row(street_name=\"KING GEORGE'S AVE\"),\n",
       " Row(street_name='HENDERSON CRES'),\n",
       " Row(street_name='GANGSA RD'),\n",
       " Row(street_name='JURONG WEST AVE 1'),\n",
       " Row(street_name='FERNVALE RD'),\n",
       " Row(street_name='HOUGANG AVE 4'),\n",
       " Row(street_name='JURONG WEST ST 41'),\n",
       " Row(street_name='RIVERVALE CRES'),\n",
       " Row(street_name='COMPASSVALE RD'),\n",
       " Row(street_name='BT BATOK WEST AVE 4'),\n",
       " Row(street_name='BUANGKOK GREEN'),\n",
       " Row(street_name='PUNGGOL CTRL'),\n",
       " Row(street_name='TAMPINES ST 33'),\n",
       " Row(street_name='TG PAGAR PLAZA'),\n",
       " Row(street_name='WEST COAST RD'),\n",
       " Row(street_name='JURONG WEST ST 74'),\n",
       " Row(street_name='JLN RAJAH'),\n",
       " Row(street_name='YISHUN AVE 7'),\n",
       " Row(street_name='SIMS AVE'),\n",
       " Row(street_name='DOVER CRES'),\n",
       " Row(street_name='REDHILL LANE'),\n",
       " Row(street_name='BENDEMEER RD'),\n",
       " Row(street_name='WOODLANDS ST 41'),\n",
       " Row(street_name='JURONG WEST ST 25'),\n",
       " Row(street_name='ADMIRALTY DR'),\n",
       " Row(street_name='SAGO LANE'),\n",
       " Row(street_name='BT MERAH CTRL'),\n",
       " Row(street_name='PANDAN GDNS'),\n",
       " Row(street_name='JURONG WEST ST 92'),\n",
       " Row(street_name='WOODLANDS AVE 5'),\n",
       " Row(street_name='HOUGANG ST 61'),\n",
       " Row(street_name='SERANGOON NTH AVE 1'),\n",
       " Row(street_name='LOR 7 TOA PAYOH'),\n",
       " Row(street_name='HOUGANG AVE 9'),\n",
       " Row(street_name='TAMPINES ST 22'),\n",
       " Row(street_name='PINE CL'),\n",
       " Row(street_name='COMPASSVALE CRES'),\n",
       " Row(street_name='KENT RD'),\n",
       " Row(street_name='BT BATOK WEST AVE 8'),\n",
       " Row(street_name='PETIR RD'),\n",
       " Row(street_name='LOMPANG RD'),\n",
       " Row(street_name='WELLINGTON CIRCLE'),\n",
       " Row(street_name='YISHUN CTRL 1'),\n",
       " Row(street_name='JURONG WEST AVE 5'),\n",
       " Row(street_name='MOULMEIN RD'),\n",
       " Row(street_name='YUNG KUANG RD'),\n",
       " Row(street_name='ANG MO KIO AVE 5'),\n",
       " Row(street_name='TOH GUAN RD'),\n",
       " Row(street_name='QUEENSWAY')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# street name\n",
    "df_pyspark.select('street_name').distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Based Problem Statement <a name = \"ps\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value based problem statement:\n",
    "\n",
    "Construct a model that predicts the resale prices of any given HDB resale transaction based on its characteristics.\\\n",
    "*characteristics can refer to (flat model, storey range, flat type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Exploratory Data Analysis and Data Cleansing <a name = \"s2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration & Analysis With PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable is resale_price\n",
    "# Explore the relationship between the features in the dataset that are relevant to the target.\n",
    "# Take note of any trends or anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Resale Price against Remaining Lease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+\n",
      "|remaining_lease| avg(resale_price)|\n",
      "+---------------+------------------+\n",
      "|           1160|          695000.0|\n",
      "|           1159|          462500.0|\n",
      "|           1158|          861000.0|\n",
      "|           1157|          839000.0|\n",
      "|           1156| 957666.6666666666|\n",
      "|           1155|          799000.0|\n",
      "|           1154|          750808.0|\n",
      "|           1153|          615777.6|\n",
      "|           1152|          488000.0|\n",
      "|           1151| 440590.6666666667|\n",
      "|           1150|         476733.28|\n",
      "|           1149| 415028.5714285714|\n",
      "|           1148| 419412.0707070707|\n",
      "|           1147|428649.15862068965|\n",
      "|           1146|444071.22424242424|\n",
      "|           1145|437010.03831417626|\n",
      "|           1144|450892.23247232474|\n",
      "|           1143|464206.31470588234|\n",
      "|           1142|          443500.0|\n",
      "|           1141| 449181.2867830424|\n",
      "+---------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resale Price and Remaining Lease (in months) top20\n",
    "df_pyspark.select([\"remaining_lease\", \"resale_price\"]).groupBy('remaining_lease').avg().sort(\"remaining_lease\", ascending=False).drop(\"avg(remaining_lease)\").show()\n",
    "# order by descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+\n",
      "|remaining_lease| avg(resale_price)|\n",
      "+---------------+------------------+\n",
      "|            553|          258700.0|\n",
      "|            554|245166.66666666666|\n",
      "|            555|          256000.0|\n",
      "|            556|          246000.0|\n",
      "|            557|          265000.0|\n",
      "|            558|231111.11111111112|\n",
      "|            559|230857.14285714287|\n",
      "|            560|236769.23076923078|\n",
      "|            561|250857.14285714287|\n",
      "|            562|221222.22222222222|\n",
      "|            563|          269564.0|\n",
      "|            564|258333.33333333334|\n",
      "|            565|          256000.0|\n",
      "|            566|230916.66666666666|\n",
      "|            567|245333.33333333334|\n",
      "|            568|245914.46153846153|\n",
      "|            569|          246649.9|\n",
      "|            570|239666.66666666666|\n",
      "|            571| 242307.6923076923|\n",
      "|            572| 247692.3076923077|\n",
      "+---------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resale Price and Remaining Lease (in months) bottom20\n",
    "df_pyspark.select([\"remaining_lease\", \"resale_price\"]).groupBy('remaining_lease').avg().sort(\"remaining_lease\", ascending=True).drop(\"avg(remaining_lease)\").show()\n",
    "# order by asc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion: It can be observed that a higher remaining lease tends to mean a higher resale price based on the comparison between the two tables above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Resale Price against Floor Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+\n",
      "|floor_area_sqm|resale_price|\n",
      "+--------------+------------+\n",
      "|         249.0|   1053888.0|\n",
      "|         237.0|   1185000.0|\n",
      "|         215.0|    900000.0|\n",
      "|         215.0|    888000.0|\n",
      "|         215.0|    830000.0|\n",
      "|         192.0|    850000.0|\n",
      "|         192.0|    800000.0|\n",
      "|         192.0|    800000.0|\n",
      "|         192.0|    780000.0|\n",
      "|         192.0|    778000.0|\n",
      "|         192.0|    760000.0|\n",
      "|         192.0|    760000.0|\n",
      "|         192.0|    755000.0|\n",
      "|         192.0|    750000.0|\n",
      "|         192.0|    738000.0|\n",
      "|         192.0|    733000.0|\n",
      "|         192.0|    729000.0|\n",
      "|         192.0|    700000.0|\n",
      "|         190.0|    750000.0|\n",
      "|         189.0|    840000.0|\n",
      "+--------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resale Price and Floor Area\n",
    "df_pyspark.select([\"floor_area_sqm\", \"resale_price\"]).sort([\"floor_area_sqm\", \"resale_price\"], ascending=False).show(20)\n",
    "# order by descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+\n",
      "|floor_area_sqm|resale_price|\n",
      "+--------------+------------+\n",
      "|          null|    275000.0|\n",
      "|          null|    275000.0|\n",
      "|          null|    300000.0|\n",
      "|          null|    315000.0|\n",
      "|          null|    320000.0|\n",
      "|          null|    325000.0|\n",
      "|          null|    328000.0|\n",
      "|          null|    330000.0|\n",
      "|          null|    330000.0|\n",
      "|          null|    340000.0|\n",
      "|          null|    350000.0|\n",
      "|          null|    352000.0|\n",
      "|          null|    355000.0|\n",
      "|          null|    360000.0|\n",
      "|          null|    360000.0|\n",
      "|          null|    363000.0|\n",
      "|          null|    365000.0|\n",
      "|          null|    380000.0|\n",
      "|          null|    383000.0|\n",
      "|          null|    383500.0|\n",
      "+--------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select([\"floor_area_sqm\", \"resale_price\"]).sort([\"floor_area_sqm\", \"resale_price\"], ascending=True).show(20)\n",
    "# order by descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion: By comparing the 2 tables, we are able to confirm that the resale price of the flat is proportional to the floor area of the flat. \n",
    "# (more area = more expensive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Resale Price by Town"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+\n",
      "|           town| avg(resale_price)|\n",
      "+---------------+------------------+\n",
      "|    BUKIT TIMAH| 714816.9735449735|\n",
      "|         BISHAN|   644789.63170347|\n",
      "|   CENTRAL AREA| 623428.0220183487|\n",
      "|    BUKIT MERAH| 564024.8797051979|\n",
      "|     QUEENSTOWN| 554835.8535597189|\n",
      "|  MARINE PARADE| 518115.9173126615|\n",
      "|KALLANG/WHAMPOA|496043.73121085594|\n",
      "|      TOA PAYOH| 494166.7532051282|\n",
      "|      PASIR RIS| 492123.0871459695|\n",
      "|      SERANGOON| 490769.0934438583|\n",
      "|       TAMPINES|474205.32034313725|\n",
      "|       CLEMENTI| 469028.6115466857|\n",
      "|        PUNGGOL| 453269.6137253925|\n",
      "|       SENGKANG|433994.11826156947|\n",
      "|        GEYLANG|430605.67181467183|\n",
      "|        HOUGANG|429212.74610328645|\n",
      "|  BUKIT PANJANG|428196.38632550335|\n",
      "|    JURONG EAST| 416185.7745504841|\n",
      "|     ANG MO KIO| 411547.1964346932|\n",
      "|          BEDOK| 410944.0495771362|\n",
      "|    JURONG WEST| 387879.4531122346|\n",
      "|  CHOA CHU KANG|384960.08120300755|\n",
      "|      SEMBAWANG| 378804.1880729761|\n",
      "|    BUKIT BATOK| 377715.2757037944|\n",
      "|      WOODLANDS|376810.78428227745|\n",
      "|         YISHUN| 359988.7258250635|\n",
      "+---------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resale Price by Town sorted in desc\n",
    "df_pyspark.select([\"town\", \"resale_price\"]).groupBy('town').avg().sort(\"avg(resale_price)\", ascending=False).show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion: It can be observed that the top 3 towns with the highest resale value is Bukit Timah, Bishan, and the Central Area. \n",
    "# It may indicate that these are high value locations in terms of housing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Resale Price by Flat Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+\n",
      "|       flat_type| avg(resale_price)|\n",
      "+----------------+------------------+\n",
      "|MULTI-GENERATION| 806804.6060606061|\n",
      "|       EXECUTIVE| 625390.6592435675|\n",
      "|          5 ROOM| 528812.8562151295|\n",
      "|          4 ROOM| 432760.1087740674|\n",
      "|          3 ROOM| 307712.2837821541|\n",
      "|          2 ROOM|233600.68988030468|\n",
      "|          1 ROOM| 186181.6551724138|\n",
      "+----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resale Price by Flat Type in desc\n",
    "df_pyspark.select([\"flat_type\", \"resale_price\"]).groupBy('flat_type').avg().sort(\"avg(resale_price)\", ascending=False).show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion: Comparing the flat types, it is clear that the most expensive flat type is a Multi-Generation Flat, while the least expensive would be a 1 Room Flat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Resale Price by Storey Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|storey_range| avg(resale_price)|\n",
      "+------------+------------------+\n",
      "|    43 TO 45|1037833.3333333334|\n",
      "|    49 TO 51|1022814.6666666666|\n",
      "|    46 TO 48|1018845.4545454546|\n",
      "|    40 TO 42|       894045.9375|\n",
      "|    37 TO 39| 845602.7674418605|\n",
      "|    34 TO 36| 802757.8962962963|\n",
      "|    31 TO 33| 800630.9291338583|\n",
      "|    28 TO 30| 751391.7605177993|\n",
      "|    25 TO 27| 666919.1401295896|\n",
      "|    22 TO 24| 610122.5498092031|\n",
      "|    19 TO 21| 591394.6781223805|\n",
      "|    16 TO 18|514570.93940520444|\n",
      "|    13 TO 15|472987.87508488825|\n",
      "|    10 TO 12|438086.75250713184|\n",
      "|    07 TO 09|423477.66865580005|\n",
      "|    04 TO 06| 412115.9694568433|\n",
      "|    01 TO 03| 394274.2836198463|\n",
      "+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resale Price by Storey Range in desc\n",
    "df_pyspark.select([\"storey_range\", \"resale_price\"]).groupBy('storey_range').avg().sort(\"avg(resale_price)\", ascending=False).show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion: From the table, it can be observed that there is a trend where the flat is priced higher if it is located on a higher storey range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Resale Price by Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|year| avg(resale_price)|\n",
      "+----+------------------+\n",
      "|2017|443849.84801951225|\n",
      "|2018|441282.06370344607|\n",
      "|2019| 432137.9129018299|\n",
      "+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resale Price by Year\n",
    "df_pyspark.select([\"year\", \"resale_price\"]).groupBy('year').avg().sort(\"avg(resale_price)\", ascending=False).drop(\"avg(year)\").show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion: The table above seems to indicate that the average resale price of flats has decreased slightly from 2017 to 2019. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine relationship between block and resale price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+\n",
      "|block|resale_price|\n",
      "+-----+------------+\n",
      "|    8|   1205000.0|\n",
      "|   1C|   1200000.0|\n",
      "|   9A|   1200000.0|\n",
      "|   1C|   1188000.0|\n",
      "|    9|   1185000.0|\n",
      "|   41|   1185000.0|\n",
      "| 273B|   1180000.0|\n",
      "|  18C|   1170000.0|\n",
      "|   1D|   1168000.0|\n",
      "| 139A|   1160888.0|\n",
      "+-----+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Relationship between block and resale price (top 10)\n",
    "df_pyspark.select([\"block\", \"resale_price\"]).sort(\"resale_price\", ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+\n",
      "|block|resale_price|\n",
      "+-----+------------+\n",
      "|    8|   1205000.0|\n",
      "|   1C|   1200000.0|\n",
      "|   9A|   1200000.0|\n",
      "|   1C|   1188000.0|\n",
      "|    9|   1185000.0|\n",
      "|   41|   1185000.0|\n",
      "| 273B|   1180000.0|\n",
      "|  18C|   1170000.0|\n",
      "|   1D|   1168000.0|\n",
      "| 139A|   1160888.0|\n",
      "+-----+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# bottom 10\n",
    "df_pyspark.select([\"block\", \"resale_price\"]).sort(\"resale_price\", ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion: There does not seem to be any relationship between the block number and the resale price of a flat. \n",
    "# Therefore, we can safely drop this feature later as it does not seem to be a helpful predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+\n",
      "|summary|   floor_area_sqm|   remaining_lease|      resale_price|\n",
      "+-------+-----------------+------------------+------------------+\n",
      "|  count|            64197|             64247|             64247|\n",
      "|   mean|97.77009984890256| 894.6413840334957|438943.70469516085|\n",
      "| stddev|24.26994610142912|149.62669792791093|153760.65294972394|\n",
      "|    min|             31.0|               553|          150000.0|\n",
      "|    max|            249.0|              1160|         1205000.0|\n",
      "+-------+-----------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Distribution of Numerical Features\n",
    "# Relevant features: (floor_area_sqm, remaining_lease, resale_price)\n",
    "# date features and irrelevant features such as block & lease commencement will not give any insight\n",
    "df_pyspark.describe(['floor_area_sqm', 'remaining_lease', 'resale_price']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----+---------+-----+-----------+------------+--------------+----------+-------------------+---------------+------------+\n",
      "|year|month|town|flat_type|block|street_name|storey_range|floor_area_sqm|flat_model|lease_commence_date|remaining_lease|resale_price|\n",
      "+----+-----+----+---------+-----+-----------+------------+--------------+----------+-------------------+---------------+------------+\n",
      "|   0|    0|   0|        0|    0|          0|           0|            50|         0|                  0|              0|           0|\n",
      "+----+-----+----+---------+-----+-----------+------------+--------------+----------+-------------------+---------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check Dataframe for NA values\n",
    "from pyspark.sql.functions import col,isnan, when, count\n",
    "df_pyspark.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_pyspark.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+-----+-----------------+------------+--------------+--------------+-------------------+---------------+------------+\n",
      "|year|month|      town|flat_type|block|      street_name|storey_range|floor_area_sqm|    flat_model|lease_commence_date|remaining_lease|resale_price|\n",
      "+----+-----+----------+---------+-----+-----------------+------------+--------------+--------------+-------------------+---------------+------------+\n",
      "|2017|    1|ANG MO KIO|   2 ROOM|  406|ANG MO KIO AVE 10|    10 TO 12|          44.0|      Improved|               1979|            736|    232000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  108| ANG MO KIO AVE 4|    01 TO 03|          67.0|New Generation|               1978|            727|    250000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  602| ANG MO KIO AVE 5|    01 TO 03|          67.0|New Generation|               1980|            749|    262000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  465|ANG MO KIO AVE 10|    04 TO 06|          68.0|New Generation|               1980|            745|    265000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  601| ANG MO KIO AVE 5|    01 TO 03|          67.0|New Generation|               1980|            749|    265000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  150| ANG MO KIO AVE 5|    01 TO 03|          68.0|New Generation|               1981|            756|    275000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  447|ANG MO KIO AVE 10|    04 TO 06|          68.0|New Generation|               1979|            738|    280000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  218| ANG MO KIO AVE 1|    04 TO 06|          67.0|New Generation|               1976|            700|    285000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  447|ANG MO KIO AVE 10|    04 TO 06|          68.0|New Generation|               1979|            738|    285000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  571| ANG MO KIO AVE 3|    01 TO 03|          67.0|New Generation|               1979|            736|    285000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  534|ANG MO KIO AVE 10|    01 TO 03|          68.0|New Generation|               1980|            745|    288500.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  233| ANG MO KIO AVE 3|    10 TO 12|          67.0|New Generation|               1977|            716|    295000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  235| ANG MO KIO AVE 3|    04 TO 06|          67.0|New Generation|               1977|            716|    295000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  219| ANG MO KIO AVE 1|    07 TO 09|          67.0|New Generation|               1977|            714|    297000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  536|ANG MO KIO AVE 10|    07 TO 09|          68.0|New Generation|               1980|            745|    298000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  230| ANG MO KIO AVE 3|    04 TO 06|          67.0|New Generation|               1978|            720|    298000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  570| ANG MO KIO AVE 3|    10 TO 12|          67.0|New Generation|               1979|            736|    300000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  624| ANG MO KIO AVE 4|    04 TO 06|          68.0|New Generation|               1980|            752|    301000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  441|ANG MO KIO AVE 10|    07 TO 09|          67.0|New Generation|               1979|            732|    306000.0|\n",
      "|2017|    1|ANG MO KIO|   3 ROOM|  625| ANG MO KIO AVE 9|    04 TO 06|          68.0|New Generation|               1980|            752|    312000.0|\n",
      "+----+-----+----------+---------+-----+-----------------+------------+--------------+--------------+-------------------+---------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# consider NaN Treatment\n",
    "# Previously identified 50 rows with NaN in floor_area_sqm\n",
    "# Considering we have 64247 rows, it is more preferable to drop the rows (have sufficient rows)\n",
    "# This is to prevent us from introducing falsified data into the dataframe (using imputation)\n",
    "# which can affect the accuracy and bias of our final model.\n",
    "df_pyspark_nan = df_pyspark.na.drop(how=\"any\")\n",
    "df_pyspark_nan.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 64197\n",
      "Number of columns: 12\n",
      "Shape of the Dataframe: (64197, 12)\n"
     ]
    }
   ],
   "source": [
    "# Dimension of new Dataframe (no NaN)\n",
    "row = df_pyspark_nan.count()\n",
    "col = len(df_pyspark_nan.columns)\n",
    " \n",
    "# display\n",
    "print(f'Number of rows: {row}')\n",
    "print(f'Number of columns: {col}')\n",
    "print(f'Shape of the Dataframe: {(row,col)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Irrelevant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+---------+------------+--------------+--------------+---------------+------------+\n",
      "|year|      town|flat_type|storey_range|floor_area_sqm|    flat_model|remaining_lease|resale_price|\n",
      "+----+----------+---------+------------+--------------+--------------+---------------+------------+\n",
      "|2017|ANG MO KIO|   2 ROOM|    10 TO 12|          44.0|      Improved|            736|    232000.0|\n",
      "|2017|ANG MO KIO|   3 ROOM|    01 TO 03|          67.0|New Generation|            727|    250000.0|\n",
      "|2017|ANG MO KIO|   3 ROOM|    01 TO 03|          67.0|New Generation|            749|    262000.0|\n",
      "|2017|ANG MO KIO|   3 ROOM|    04 TO 06|          68.0|New Generation|            745|    265000.0|\n",
      "|2017|ANG MO KIO|   3 ROOM|    01 TO 03|          67.0|New Generation|            749|    265000.0|\n",
      "|2017|ANG MO KIO|   3 ROOM|    01 TO 03|          68.0|New Generation|            756|    275000.0|\n",
      "|2017|ANG MO KIO|   3 ROOM|    04 TO 06|          68.0|New Generation|            738|    280000.0|\n",
      "|2017|ANG MO KIO|   3 ROOM|    04 TO 06|          67.0|New Generation|            700|    285000.0|\n",
      "|2017|ANG MO KIO|   3 ROOM|    04 TO 06|          68.0|New Generation|            738|    285000.0|\n",
      "|2017|ANG MO KIO|   3 ROOM|    01 TO 03|          67.0|New Generation|            736|    285000.0|\n",
      "|2017|ANG MO KIO|   3 ROOM|    01 TO 03|          68.0|New Generation|            745|    288500.0|\n",
      "|2017|ANG MO KIO|   3 ROOM|    10 TO 12|          67.0|New Generation|            716|    295000.0|\n",
      "|2017|ANG MO KIO|   3 ROOM|    04 TO 06|          67.0|New Generation|            716|    295000.0|\n",
      "|2017|ANG MO KIO|   3 ROOM|    07 TO 09|          67.0|New Generation|            714|    297000.0|\n",
      "|2017|ANG MO KIO|   3 ROOM|    07 TO 09|          68.0|New Generation|            745|    298000.0|\n",
      "|2017|ANG MO KIO|   3 ROOM|    04 TO 06|          67.0|New Generation|            720|    298000.0|\n",
      "|2017|ANG MO KIO|   3 ROOM|    10 TO 12|          67.0|New Generation|            736|    300000.0|\n",
      "|2017|ANG MO KIO|   3 ROOM|    04 TO 06|          68.0|New Generation|            752|    301000.0|\n",
      "|2017|ANG MO KIO|   3 ROOM|    07 TO 09|          67.0|New Generation|            732|    306000.0|\n",
      "|2017|ANG MO KIO|   3 ROOM|    04 TO 06|          68.0|New Generation|            752|    312000.0|\n",
      "+----+----------+---------+------------+--------------+--------------+---------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove irrelevant columns (only block, street_name, month, and lease_commence_date for now)\n",
    "# will not be useful for prediction based on exploratory analysis.\n",
    "df_pyspark_new = df_pyspark_nan.drop('block','lease_commence_date','street_name','month')\n",
    "df_pyspark_new.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Wrangling and Transformation <a name = \"s3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark_final = df_pyspark_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "(train, test) = df_pyspark_final.randomSplit([0.8, 0.2], seed=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Show train type\n",
    "print(type(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show train and test dimensions after split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 51337\n",
      "Number of columns: 8\n",
      "Shape of the Dataframe: (51337, 8)\n"
     ]
    }
   ],
   "source": [
    "# Display train\n",
    "row = train.count()\n",
    "col = len(train.columns)\n",
    "print(f'Number of rows: {row}')\n",
    "print(f'Number of columns: {col}')\n",
    "print(f'Shape of the Dataframe: {(row,col)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 12860\n",
      "Number of columns: 8\n",
      "Shape of the Dataframe: (12860, 8)\n"
     ]
    }
   ],
   "source": [
    "# Display test\n",
    "row = test.count()\n",
    "col = len(test.columns)\n",
    "print(f'Number of rows: {row}')\n",
    "print(f'Number of columns: {col}')\n",
    "print(f'Shape of the Dataframe: {(row,col)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+---------+------------+--------------+----------+---------------+------------+\n",
      "|year|      town|flat_type|storey_range|floor_area_sqm|flat_model|remaining_lease|resale_price|\n",
      "+----+----------+---------+------------+--------------+----------+---------------+------------+\n",
      "|2017|ANG MO KIO|   2 ROOM|    01 TO 03|          44.0|  Improved|            743|    215000.0|\n",
      "|2017|ANG MO KIO|   2 ROOM|    01 TO 03|          44.0|  Improved|            743|    220000.0|\n",
      "|2017|ANG MO KIO|   2 ROOM|    01 TO 03|          45.0|  Improved|            815|    205000.0|\n",
      "|2017|ANG MO KIO|   2 ROOM|    04 TO 06|          44.0|  Improved|            712|    233000.0|\n",
      "|2017|ANG MO KIO|   2 ROOM|    04 TO 06|          44.0|  Improved|            713|    240000.0|\n",
      "+----+----------+---------+------------+--------------+----------+---------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display train rows (5)\n",
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+---------+------------+--------------+--------------+---------------+------------+\n",
      "|year|      town|flat_type|storey_range|floor_area_sqm|    flat_model|remaining_lease|resale_price|\n",
      "+----+----------+---------+------------+--------------+--------------+---------------+------------+\n",
      "|2017|ANG MO KIO|   2 ROOM|    04 TO 06|          44.0|      Improved|            717|    210000.0|\n",
      "|2017|ANG MO KIO|   2 ROOM|    07 TO 09|          44.0|      Improved|            713|    245000.0|\n",
      "|2017|ANG MO KIO|   2 ROOM|    10 TO 12|          44.0|      Improved|            717|    250000.0|\n",
      "|2017|ANG MO KIO|   3 ROOM|    01 TO 03|          67.0|New Generation|            695|    282000.0|\n",
      "|2017|ANG MO KIO|   3 ROOM|    01 TO 03|          67.0|New Generation|            711|    325000.0|\n",
      "+----+----------+---------+------------+--------------+--------------+---------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display train rows (5)\n",
    "test.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries (OHE & String Indexing)\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical features to be transformed\n",
    "strings_used = [\"town\",\"flat_type\",\"flat_model\",\"storey_range\"] # defines which column will be encoded add another one by adding the column name to the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform String Indexing for Categorical columns(town, flat type, flat model, storey range)\n",
    "#stage_string = [StringIndexer(inputCol= c, outputCol= c+\"_string_encoded\") for c in strings_used]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit to train\n",
    "#train_string_indexed = stage_string.fit(train).transform(train)\n",
    "#train_string_indexed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit to test\n",
    "#test_string_indexed = stage_string.fit(test).transform(test)\n",
    "#test_string_indexed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform One-Hot Encoding for Categorical columns(town, flat type, flat model, storey range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stage_one_hot = [OneHotEncoder(inputCol= c+\"_string_encoded\", outputCol= c+ \"_one_hot\") for c in strings_used]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# has to be string indexed first as OneHotEncoder only converts category indices and not the original categorical values\n",
    "#train_ohe = stage_one_hot.fit(train_string_indexed).transform(train_string_indexed)\n",
    "#train_ohe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_ohe = stage_one_hot.fit(test_string_indexed).transform(test_string_indexed)\n",
    "#test_ohe.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding Pipeline (One-Hot Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+---------+------------+--------------+----------+---------------+------------+-------------------+------------------------+-------------------------+---------------------------+--------------+-----------------+------------------+--------------------+\n",
      "|year|      town|flat_type|storey_range|floor_area_sqm|flat_model|remaining_lease|resale_price|town_string_encoded|flat_type_string_encoded|flat_model_string_encoded|storey_range_string_encoded|  town_one_hot|flat_type_one_hot|flat_model_one_hot|storey_range_one_hot|\n",
      "+----+----------+---------+------------+--------------+----------+---------------+------------+-------------------+------------------------+-------------------------+---------------------------+--------------+-----------------+------------------+--------------------+\n",
      "|2017|ANG MO KIO|   2 ROOM|    01 TO 03|          44.0|  Improved|            743|    215000.0|                8.0|                     4.0|                      1.0|                        3.0|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[3],[1.0])|\n",
      "|2017|ANG MO KIO|   2 ROOM|    01 TO 03|          44.0|  Improved|            743|    220000.0|                8.0|                     4.0|                      1.0|                        3.0|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[3],[1.0])|\n",
      "|2017|ANG MO KIO|   2 ROOM|    01 TO 03|          45.0|  Improved|            815|    205000.0|                8.0|                     4.0|                      1.0|                        3.0|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[3],[1.0])|\n",
      "|2017|ANG MO KIO|   2 ROOM|    04 TO 06|          44.0|  Improved|            712|    233000.0|                8.0|                     4.0|                      1.0|                        0.0|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[0],[1.0])|\n",
      "|2017|ANG MO KIO|   2 ROOM|    04 TO 06|          44.0|  Improved|            713|    240000.0|                8.0|                     4.0|                      1.0|                        0.0|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[0],[1.0])|\n",
      "+----+----------+---------+------------+--------------+----------+---------------+------------+-------------------+------------------------+-------------------------+---------------------------+--------------+-----------------+------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pipeline (does both at once) (Full OHE)\n",
    "strings_used = [\"town\",\"flat_type\",\"flat_model\",\"storey_range\"] \n",
    "\n",
    "stage_string = [StringIndexer(inputCol= c, outputCol= c+\"_string_encoded\") for c in strings_used]\n",
    "stage_one_hot = [OneHotEncoder(inputCol= c+\"_string_encoded\", outputCol= c+ \"_one_hot\") for c in strings_used]\n",
    "\n",
    "ppl = Pipeline(stages= stage_string + stage_one_hot)\n",
    "train_index_ohe = ppl.fit(train).transform(train)\n",
    "test_index_ohe = ppl.fit(test).transform(test)\n",
    "train_index_ohe.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+---------------+------------+-------------------+------------------------+-------------------------+---------------------------+--------------+-----------------+------------------+--------------------+\n",
      "|year|floor_area_sqm|remaining_lease|resale_price|town_string_encoded|flat_type_string_encoded|flat_model_string_encoded|storey_range_string_encoded|  town_one_hot|flat_type_one_hot|flat_model_one_hot|storey_range_one_hot|\n",
      "+----+--------------+---------------+------------+-------------------+------------------------+-------------------------+---------------------------+--------------+-----------------+------------------+--------------------+\n",
      "|2017|          44.0|            743|    215000.0|                8.0|                     4.0|                      1.0|                        3.0|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[3],[1.0])|\n",
      "|2017|          44.0|            743|    220000.0|                8.0|                     4.0|                      1.0|                        3.0|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[3],[1.0])|\n",
      "|2017|          45.0|            815|    205000.0|                8.0|                     4.0|                      1.0|                        3.0|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[3],[1.0])|\n",
      "|2017|          44.0|            712|    233000.0|                8.0|                     4.0|                      1.0|                        0.0|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[0],[1.0])|\n",
      "|2017|          44.0|            713|    240000.0|                8.0|                     4.0|                      1.0|                        0.0|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[0],[1.0])|\n",
      "|2017|          44.0|            747|    230000.0|                8.0|                     4.0|                      1.0|                        0.0|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[0],[1.0])|\n",
      "|2017|          45.0|            808|    228000.0|                8.0|                     4.0|                      1.0|                        0.0|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[0],[1.0])|\n",
      "|2017|          45.0|            813|    210000.0|                8.0|                     4.0|                      1.0|                        0.0|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[0],[1.0])|\n",
      "|2017|          44.0|            713|    222000.0|                8.0|                     4.0|                      1.0|                        1.0|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[1],[1.0])|\n",
      "|2017|          44.0|            713|    230000.0|                8.0|                     4.0|                      1.0|                        1.0|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[1],[1.0])|\n",
      "|2017|          44.0|            715|    249000.0|                8.0|                     4.0|                      1.0|                        1.0|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[1],[1.0])|\n",
      "|2017|          44.0|            715|    250000.0|                8.0|                     4.0|                      1.0|                        1.0|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[1],[1.0])|\n",
      "|2017|          44.0|            745|    255000.0|                8.0|                     4.0|                      1.0|                        1.0|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[1],[1.0])|\n",
      "|2017|          44.0|            746|    239000.0|                8.0|                     4.0|                      1.0|                        1.0|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[1],[1.0])|\n",
      "|2017|          44.0|            748|    238000.0|                8.0|                     4.0|                      1.0|                        1.0|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[1],[1.0])|\n",
      "|2017|          45.0|            811|    233000.0|                8.0|                     4.0|                      1.0|                        1.0|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[1],[1.0])|\n",
      "|2017|          44.0|            706|    257000.0|                8.0|                     4.0|                      1.0|                        2.0|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[2],[1.0])|\n",
      "|2017|          44.0|            709|    230000.0|                8.0|                     4.0|                      1.0|                        2.0|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[2],[1.0])|\n",
      "|2017|          44.0|            733|    235000.0|                8.0|                     4.0|                      1.0|                        2.0|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[2],[1.0])|\n",
      "|2017|          44.0|            736|    232000.0|                8.0|                     4.0|                      1.0|                        2.0|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[2],[1.0])|\n",
      "+----+--------------+---------------+------------+-------------------+------------------------+-------------------------+---------------------------+--------------+-----------------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop original columns from both (town, flat type, flat model, storey range)\n",
    "# They have been encoded into numerical values suitable for machine learning modelling\n",
    "train_index_ohe = train_index_ohe.drop('town','flat_type','flat_model','storey_range')\n",
    "test_index_ohe = test_index_ohe.drop('town','flat_type','flat_model','storey_range')\n",
    "train_index_ohe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep OHE values only\n",
    "train_index_ohe = train_index_ohe.select(\"year\", \"floor_area_sqm\", \"remaining_lease\", \"town_one_hot\", \"flat_type_one_hot\", \"flat_model_one_hot\", \"storey_range_one_hot\", \"resale_price\")\n",
    "test_index_ohe = test_index_ohe.select(\"year\", \"floor_area_sqm\", \"remaining_lease\", \"town_one_hot\", \"flat_type_one_hot\", \"flat_model_one_hot\", \"storey_range_one_hot\", \"resale_price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remaining Lease to Year (Final Keep Month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+---------------+--------------+-----------------+------------------+--------------------+------------+----------------------+\n",
      "|year|floor_area_sqm|remaining_lease|  town_one_hot|flat_type_one_hot|flat_model_one_hot|storey_range_one_hot|resale_price|remaining_lease (year)|\n",
      "+----+--------------+---------------+--------------+-----------------+------------------+--------------------+------------+----------------------+\n",
      "|2017|          44.0|            743|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[3],[1.0])|    215000.0|    61.916666666666664|\n",
      "|2017|          44.0|            743|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[3],[1.0])|    220000.0|    61.916666666666664|\n",
      "|2017|          45.0|            815|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[3],[1.0])|    205000.0|     67.91666666666667|\n",
      "|2017|          44.0|            712|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[0],[1.0])|    233000.0|    59.333333333333336|\n",
      "|2017|          44.0|            713|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[0],[1.0])|    240000.0|    59.416666666666664|\n",
      "|2017|          44.0|            747|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[0],[1.0])|    230000.0|                 62.25|\n",
      "|2017|          45.0|            808|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[0],[1.0])|    228000.0|     67.33333333333333|\n",
      "|2017|          45.0|            813|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[0],[1.0])|    210000.0|                 67.75|\n",
      "|2017|          44.0|            713|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[1],[1.0])|    222000.0|    59.416666666666664|\n",
      "|2017|          44.0|            713|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[1],[1.0])|    230000.0|    59.416666666666664|\n",
      "|2017|          44.0|            715|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[1],[1.0])|    249000.0|    59.583333333333336|\n",
      "|2017|          44.0|            715|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[1],[1.0])|    250000.0|    59.583333333333336|\n",
      "|2017|          44.0|            745|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[1],[1.0])|    255000.0|    62.083333333333336|\n",
      "|2017|          44.0|            746|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[1],[1.0])|    239000.0|    62.166666666666664|\n",
      "|2017|          44.0|            748|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[1],[1.0])|    238000.0|    62.333333333333336|\n",
      "|2017|          45.0|            811|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[1],[1.0])|    233000.0|     67.58333333333333|\n",
      "|2017|          44.0|            706|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[2],[1.0])|    257000.0|    58.833333333333336|\n",
      "|2017|          44.0|            709|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[2],[1.0])|    230000.0|    59.083333333333336|\n",
      "|2017|          44.0|            733|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[2],[1.0])|    235000.0|    61.083333333333336|\n",
      "|2017|          44.0|            736|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[2],[1.0])|    232000.0|    61.333333333333336|\n",
      "+----+--------------+---------------+--------------+-----------------+------------------+--------------------+------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert remaining lease into year instead of month (put in transformation)\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import col\n",
    "train_index_t = train_index_ohe.withColumn(\"remaining_lease (year)\", col(\"remaining_lease\") / 12)\n",
    "#train_index_t = train_index_ohe.withColumn(\"remaining_lease (year)\", f.round('remaining_lease (year)',2)) do not round for more accurate values\n",
    "#train_index_t = train_index_ohe.drop('remaining_lease')\n",
    "train_index_t.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+---------------+--------------+-----------------+------------------+--------------------+------------+----------------------+\n",
      "|year|floor_area_sqm|remaining_lease|  town_one_hot|flat_type_one_hot|flat_model_one_hot|storey_range_one_hot|resale_price|remaining_lease (year)|\n",
      "+----+--------------+---------------+--------------+-----------------+------------------+--------------------+------------+----------------------+\n",
      "|2017|          44.0|            717|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[0],[1.0])|    210000.0|                 59.75|\n",
      "|2017|          44.0|            713|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[1],[1.0])|    245000.0|    59.416666666666664|\n",
      "|2017|          44.0|            717|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[2],[1.0])|    250000.0|                 59.75|\n",
      "|2017|          67.0|            695|(25,[8],[1.0])|    (6,[2],[1.0])|    (18,[2],[1.0])|      (16,[3],[1.0])|    282000.0|    57.916666666666664|\n",
      "|2017|          67.0|            711|(25,[8],[1.0])|    (6,[2],[1.0])|    (18,[2],[1.0])|      (16,[3],[1.0])|    325000.0|                 59.25|\n",
      "|2017|          67.0|            724|(25,[8],[1.0])|    (6,[2],[1.0])|    (18,[2],[1.0])|      (16,[3],[1.0])|    264000.0|    60.333333333333336|\n",
      "|2017|          67.0|            726|(25,[8],[1.0])|    (6,[2],[1.0])|    (18,[2],[1.0])|      (16,[3],[1.0])|    250000.0|                  60.5|\n",
      "|2017|          67.0|            729|(25,[8],[1.0])|    (6,[2],[1.0])|    (18,[2],[1.0])|      (16,[3],[1.0])|    285000.0|                 60.75|\n",
      "|2017|          67.0|            763|(25,[8],[1.0])|    (6,[2],[1.0])|    (18,[2],[1.0])|      (16,[3],[1.0])|    280000.0|    63.583333333333336|\n",
      "|2017|          67.0|            793|(25,[8],[1.0])|    (6,[2],[1.0])|    (18,[2],[1.0])|      (16,[3],[1.0])|    320000.0|     66.08333333333333|\n",
      "|2017|          68.0|            741|(25,[8],[1.0])|    (6,[2],[1.0])|    (18,[2],[1.0])|      (16,[3],[1.0])|    290000.0|                 61.75|\n",
      "|2017|          68.0|            742|(25,[8],[1.0])|    (6,[2],[1.0])|    (18,[2],[1.0])|      (16,[3],[1.0])|    260000.0|    61.833333333333336|\n",
      "|2017|          68.0|            742|(25,[8],[1.0])|    (6,[2],[1.0])|    (18,[2],[1.0])|      (16,[3],[1.0])|    265000.0|    61.833333333333336|\n",
      "|2017|          68.0|            742|(25,[8],[1.0])|    (6,[2],[1.0])|    (18,[2],[1.0])|      (16,[3],[1.0])|    283000.0|    61.833333333333336|\n",
      "|2017|          68.0|            744|(25,[8],[1.0])|    (6,[2],[1.0])|    (18,[2],[1.0])|      (16,[3],[1.0])|    330000.0|                  62.0|\n",
      "|2017|          68.0|            745|(25,[8],[1.0])|    (6,[2],[1.0])|    (18,[2],[1.0])|      (16,[3],[1.0])|    288500.0|    62.083333333333336|\n",
      "|2017|          68.0|            747|(25,[8],[1.0])|    (6,[2],[1.0])|    (18,[2],[1.0])|      (16,[3],[1.0])|    278000.0|                 62.25|\n",
      "|2017|          68.0|            750|(25,[8],[1.0])|    (6,[2],[1.0])|    (18,[2],[1.0])|      (16,[3],[1.0])|    275000.0|                  62.5|\n",
      "|2017|          68.0|            751|(25,[8],[1.0])|    (6,[2],[1.0])|    (18,[2],[1.0])|      (16,[3],[1.0])|    260000.0|    62.583333333333336|\n",
      "|2017|          68.0|            752|(25,[8],[1.0])|    (6,[2],[1.0])|    (18,[2],[1.0])|      (16,[3],[1.0])|    305000.0|    62.666666666666664|\n",
      "+----+--------------+---------------+--------------+-----------------+------------------+--------------------+------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_index_t = test_index_ohe.withColumn(\"remaining_lease (year)\", col(\"remaining_lease\") / 12)\n",
    "#test_index_t = test_index_ohe.drop('remaining_lease')\n",
    "test_index_t.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidating Features into Xcols\n",
    "# append target variable to the end\n",
    "# Keep remaining_lease in month\n",
    "train_index_t = train_index_t.select(\"year\", \"floor_area_sqm\", \"remaining_lease\", \"town_one_hot\", \"flat_type_one_hot\", \"flat_model_one_hot\", \"storey_range_one_hot\", \"resale_price\")\n",
    "\n",
    "test_index_t = test_index_t.select(\"year\", \"floor_area_sqm\", \"remaining_lease\", \"town_one_hot\", \"flat_type_one_hot\", \"flat_model_one_hot\", \"storey_range_one_hot\", \"resale_price\")\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "featureassembler=VectorAssembler(inputCols=test_index_t.columns[:-1],outputCol=\"Xcols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "train_vectored = featureassembler.transform(train_index_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+---------------+--------------+-----------------+------------------+--------------------+------------+--------------------+\n",
      "|year|floor_area_sqm|remaining_lease|  town_one_hot|flat_type_one_hot|flat_model_one_hot|storey_range_one_hot|resale_price|               Xcols|\n",
      "+----+--------------+---------------+--------------+-----------------+------------------+--------------------+------------+--------------------+\n",
      "|2017|          44.0|            743|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[3],[1.0])|    215000.0|(68,[0,1,2,11,32,...|\n",
      "|2017|          44.0|            743|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[3],[1.0])|    220000.0|(68,[0,1,2,11,32,...|\n",
      "|2017|          45.0|            815|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[3],[1.0])|    205000.0|(68,[0,1,2,11,32,...|\n",
      "|2017|          44.0|            712|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[0],[1.0])|    233000.0|(68,[0,1,2,11,32,...|\n",
      "|2017|          44.0|            713|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[0],[1.0])|    240000.0|(68,[0,1,2,11,32,...|\n",
      "+----+--------------+---------------+--------------+-----------------+------------------+--------------------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_vectored.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "test_vectored = featureassembler.transform(test_index_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+---------------+--------------+-----------------+------------------+--------------------+------------+--------------------+\n",
      "|year|floor_area_sqm|remaining_lease|  town_one_hot|flat_type_one_hot|flat_model_one_hot|storey_range_one_hot|resale_price|               Xcols|\n",
      "+----+--------------+---------------+--------------+-----------------+------------------+--------------------+------------+--------------------+\n",
      "|2017|          44.0|            717|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[0],[1.0])|    210000.0|(68,[0,1,2,11,32,...|\n",
      "|2017|          44.0|            713|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[1],[1.0])|    245000.0|(68,[0,1,2,11,32,...|\n",
      "|2017|          44.0|            717|(25,[8],[1.0])|    (6,[4],[1.0])|    (18,[1],[1.0])|      (16,[2],[1.0])|    250000.0|(68,[0,1,2,11,32,...|\n",
      "|2017|          67.0|            695|(25,[8],[1.0])|    (6,[2],[1.0])|    (18,[2],[1.0])|      (16,[3],[1.0])|    282000.0|(68,[0,1,2,11,30,...|\n",
      "|2017|          67.0|            711|(25,[8],[1.0])|    (6,[2],[1.0])|    (18,[2],[1.0])|      (16,[3],[1.0])|    325000.0|(68,[0,1,2,11,30,...|\n",
      "+----+--------------+---------------+--------------+-----------------+------------------+--------------------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_vectored.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling on Xcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler\n",
    "\n",
    "Scaler = StandardScaler(withMean=True, withStd=True, inputCol=\"Xcols\", outputCol=\"Xcols_scaled\")\n",
    "yScaler = StandardScaler(withMean=True, withStd=True, inputCol=\"resale_price\", outputCol=\"resale_price\")\n",
    "# Standard scaler uses Z-score to perform scaling (withMean=True, withStd=True,)\n",
    "# MinMaxScaler rescales each feature individually to a common range [min, max] linearly\n",
    "# Robust Scaler removes the median and scales the data according to the quantile range (Default IQR)\n",
    "# MaxAbsScaler rescales each feature individually to range [-1, 1] by dividing through the largest maximum absolute value in each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectored = train_vectored.withColumn(\"resale_price\",train_vectored.resale_price.cast('integer'))\n",
    "test_vectored = test_vectored.withColumn(\"resale_price\",test_vectored.resale_price.cast('integer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "requirement failed: Column resale_price must be of type struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually int.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [66]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Scale Train\u001b[39;00m\n\u001b[0;32m      2\u001b[0m train_scaled \u001b[38;5;241m=\u001b[39m Scaler\u001b[38;5;241m.\u001b[39mfit(train_vectored)\u001b[38;5;241m.\u001b[39mtransform(train_vectored)\n\u001b[1;32m----> 3\u001b[0m ytrain_scaled \u001b[38;5;241m=\u001b[39m \u001b[43myScaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_vectored\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(train_vectored)\n\u001b[0;32m      4\u001b[0m train_scaled\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mC:\\apps\\spark-3.0.0-bin-hadoop2.7\\python\\pyspark\\ml\\base.py:129\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 129\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    132\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params))\n",
      "File \u001b[1;32mC:\\apps\\spark-3.0.0-bin-hadoop2.7\\python\\pyspark\\ml\\wrapper.py:321\u001b[0m, in \u001b[0;36mJavaEstimator._fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset):\n\u001b[1;32m--> 321\u001b[0m     java_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(java_model)\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copyValues(model)\n",
      "File \u001b[1;32mC:\\apps\\spark-3.0.0-bin-hadoop2.7\\python\\pyspark\\ml\\wrapper.py:318\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;124;03mFits a Java model to the input dataset.\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;124;03m:return: fitted Java model\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[1;32m--> 318\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\apps\\spark-3.0.0-bin-hadoop2.7\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[1;32mC:\\apps\\spark-3.0.0-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py:137\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    133\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconverted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(e)\u001b[0m\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m: requirement failed: Column resale_price must be of type struct<type:tinyint,size:int,indices:array<int>,values:array<double>> but was actually int."
     ]
    }
   ],
   "source": [
    "# Scale Train\n",
    "train_scaled = Scaler.fit(train_vectored).transform(train_vectored)\n",
    "ytrain_scaled = yScaler.fit(train_vectored).transform(train_vectored)\n",
    "train_scaled.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Scale Test\n",
    "test_scaled = Scaler.fit(test_vectored).transform(test_vectored)\n",
    "ytest_scaled = yScaler.fit(test_vectored).transform(test_vectored)\n",
    "test_scaled.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Machine Learning Modelling <a name = \"s4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use code to show number of rows and columns,\n",
    "# as well as a sample of 10 rows before heading into Machine Learning Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Data (train_data = final)\n",
    "# train\n",
    "train_data = train_scaled.select(\"Xcols_scaled\",\"resale_price\")\n",
    "train_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test (test_data = final)\n",
    "test_data = test_scaled.select(\"Xcols_scaled\",\"resale_price\")\n",
    "test_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show train final dimensions\n",
    "row = train_data.count()\n",
    "col = len(train_data.columns)\n",
    " \n",
    "# display\n",
    "print(f'Number of rows: {row}')\n",
    "print(f'Number of columns: {col}')\n",
    "print(f'Shape of the Dataframe: {(row,col)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show test final dimensions\n",
    "row = test_data.count()\n",
    "col = len(test_data.columns)\n",
    " \n",
    "# display\n",
    "print(f'Number of rows: {row}')\n",
    "print(f'Number of columns: {col}')\n",
    "print(f'Shape of the Dataframe: {(row,col)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "regressor=LinearRegression(featuresCol=\"Xcols_scaled\", labelCol='resale_price')\n",
    "regressor=regressor.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients\n",
    "regressor.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intercept\n",
    "regressor.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first row values of Xcols_sscaled\n",
    "train_data.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Model Evaluation and Selection <a name = \"s5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_results=regressor.evaluate(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_results.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_results=regressor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_results.predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train MAE: {train_pred_results.meanAbsoluteError}')\n",
    "print(f'train MSE: {train_pred_results.meanSquaredError}')\n",
    "print(f'train R^2: {train_pred_results.r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'test MAE: {test_pred_results.meanAbsoluteError}')\n",
    "print(f'test MSE: {test_pred_results.meanSquaredError}')\n",
    "print(f'test R^2: {test_pred_results.r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyspark_five_rows = test_data.limit(5)\n",
    "pyspark_five_rows.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.evaluate(pyspark_five_rows).predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Report <a name = \"rpt\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "6.1 [Problem Statement Formulation](#psf)\\\n",
    "&emsp; 6.1.1 [Load, Explore and Understand Data](#leu)\\\n",
    "&emsp; 6.1.2 [Formulate Value Based Problem Statement](#fps)\\\n",
    "6.2 [Exploratory Data Analysis and Data Cleansing](#eda)\\\n",
    "&emsp; 6.2.1 [Interesting Trends and Anomalies](#ta)\\\n",
    "&emsp; 6.2.2 [Potential Errors & Handling Missing Values](#mis)\\\n",
    "6.3 [Data Wrangling and Transformation](#dw)\\\n",
    "&emsp; 6.3.1  [Dropping Irrelevant Features](#dw1)\\\n",
    "&emsp; 6.3.2  [Categorical Transformation](#dw2)\\\n",
    "&emsp; 6.3.3  [Numerical Transformation](#dw3)\\\n",
    "6.4 [Machine Learning Modelling](#ml)\\\n",
    "&emsp; 6.4.1  [Validating Data](#ml1)\\\n",
    "&emsp; 6.4.2  [Sample of 10 Rows Before Modelling](#ml2)\\\n",
    "&emsp; 6.4.3  [Building the Predictive Model](#ml3)\\\n",
    "6.5 [Model Evaluation and Selectionr](#eval)\\\n",
    "&emsp; 6.5.1  [Evaluation of Predictive Model](#eval1)\\\n",
    "&emsp; 6.5.2  [Compare Models and Final Model](#eval2)\\\n",
    "6.6 [Summary and Further Improvements](#sum)\\\n",
    "&emsp; 6.4.1  [Summary of Findings](#sum1)\\\n",
    "&emsp; 6.4.2  [Further Improvements](#sum2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Problem Statement Formulation <a name = \"psf\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.1 Load, Explore and Understand Data<a name = \"leu\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report aims to cover and explain my findings and the processes involved in building a machine learning model. \n",
    "\n",
    "Before modelling, we first have to formulate a value-based prediction problem statement to help us transform the data and build a model to evaluate the dataset. To form the problem statement, pyspark is employed to load and convert the csv file into a dataframe df_pyspark for exploration.\n",
    "\n",
    "For exploration, functions such as .printSchema(), .show(), and .describe() was used to give an overview of the features present, the data types for each feature, and a brief statistical summary of the numerical features in the dataset. To display the dimensions of the dataset, a combination of .count and len() functions was used. Lastly, the unique values in the categorical features were identified using .distinct() and .collect().\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.2 Formulate Value Based Problem Statement <a name = \"fps\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the initial exploration of the dataset, the problem statement formed is Construct a model that predicts the resale prices of any given HDB resale transaction based on its characteristics, where characteristics can refer to flat model, storey range, flat type, etc. \n",
    "\n",
    "This model will be helpful to give potential buyers or sellers a rough estimate on the resale price of their HDB flat. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Exploratory Data Analysis and Data Cleansing <a name = \"eda\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis (EDA) is conducted to better understand the trends, relationships, and potential errors within the dataset. Exploratory Data Analysis is done using pyspark tables using aggregate functions as well as functions such as .groupby() and .select().\n",
    "\n",
    "Analysis of the features will be done in relation to the target, resale_price.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2.1 Interesting Trends and Anomalies <a name = \"ta\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When exploring the features, a common trend observed is, flats are priced higher when remaining lease, floor area and storey range is higher. These are features that will be useful for model prediction. Another observation is that there is a downward trend in average resale price from 2017 to 2019.  \n",
    "\n",
    "It can also be observed that the top 3 towns with the highest resale value is Bukit Timah, Bishan, and the Central Area. This may indicate that these are high value locations.\n",
    "\n",
    "No connection was observed between the block number and resale price. Therefore, we can safely drop this feature later.\n",
    "\n",
    "There is an anomaly in remaining lease as the values are in the hundreds despite the max lease being 99 years. After investigating, it was found that remaining lease was stored in months instead of years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2.2 Potential Errors & Handling Missing Values <a name = \"mis\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values were also found in floor_area_sqm. There was a total of 50 missing rows in the dataset. Considering we have 64247 rows; it is preferable to drop the rows as we would still have sufficient data for prediction. Dropping is preferred as imputation may introduce falsified data which can affect the accuracy of and bias of the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Data Wrangling and Transformation <a name = \"dw\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.1 Dropping Irrelevant Features <a name = \"dw1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before transformation, the data was further cleansed by removing the unnecessary features identified during that data exploration process. These features are,\n",
    "\n",
    "-\tblock, which has little correlation with the target.\n",
    "-\tlease_commence_date, which has no purpose as remaining_lease is derived it.\n",
    "-\tstreet_name and month adds insignificant value in relation to the target.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.2 Categorical Transformation <a name = \"dw2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the categorical features, one-hot encoding was used to encode the categorical features into a distinct value readable by the model. To perform One-Hot encoding with pyspark, the features were encoded using string indexing with StringIndexer, transformed into a binary vector with One-hot Encoder. The Pipeline function was used to perform both steps on the categorical features, \"town\",\"flat_type\",\"flat_model\",\"storey_range\". Finally, the string_encoded and original columns are dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.3 Numerical Transformation <a name = \"dw3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For numerical transformation, Vector Assembler and Feature Scaling was utilized. Vector Assembler was used to combine the columns, apart from resale_price, into a single vector column. This is done as Spark MLlib models only accept vectorized columns to maximize efficiency and scaling. \n",
    "\n",
    "Then scaling was applied onto the vectorized columns. Feature scaling is done to reduce the varying magnitude between features, to ensure that the weights of the model is not skewed. The following scalers were tested,\n",
    "\n",
    "\tStandard Scaler uses Z-score to perform scaling.\n",
    "\tMin-Max Scaler rescales each feature to a common range [min, max] linearly.\n",
    "\tRobust Scaler removes the median and scales the data based on quantile range (Default IQR).\n",
    "\tMax-Abs Scaler rescales each feature to range [-1, 1] by dividing through the largest maximum absolute value in each feature.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Machine Learning Modelling <a name = \"ml\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.1 Validating Data <a name = \"ml1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before inputting the train data into the model, the number of rows and columns of the train and test datasets were checked with .count() and len(). This is to validate the data and ensure that the predicted results are not trivial or unrealistic.\n",
    "\n",
    "Train:\n",
    "- Number of rows: 51337\n",
    "- Number of columns: 2\n",
    "- Shape of the Dataframe: (51337, 2)\n",
    "\n",
    "Test\n",
    "- Number of rows: 12860\n",
    "- Number of columns: 2\n",
    "- Shape of the Dataframe: (12860, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.2 Sample of 10 Rows Before Modelling <a name = \"ml2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the final features of the data that will be used for building the machine learning model.\n",
    "\n",
    "- Predictor Features: \"year\", \"floor_area_sqm\", \"remaining_lease\", \"town_one_hot\", \"flat_type_one_hot\", \"flat_model_one_hot\", \"storey_range_one_hot\".\n",
    "\n",
    "- Xcols_scaled: a vectorized column that consists of all the predictor features scaled using feature scaling. Used as the featuresCol.\n",
    "\n",
    "- Target Variable: \"resale_price\". Used as the labelCol.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.3 Building the Predictive Model <a name = \"ml3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model used will be a Linear Regression model as it is the model best suited for the given scenario. This is because we are building a predictive model which predicts the numerical value for a target variable, resale_price, based on its predictor features, Xcols_scaled. The model is built with the LinearRegression function imported from Spark MLlib. The model is then trained and fitted with the train dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Model Evaluation and Selection <a name = \"eval\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5.1 Evaluation of Predictive Model <a name = \"eval1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the model, regressor.evaluate() and .predictions.show() was used on both the train and test data to obtain the models predicted values. This allows us to obtain metrics that will be useful for evaluating the models performance. Since we are building a linear regression model, we will be using Mean Squared Error, Mean Absolute Error, and R-Squared as the metrics to evaluate performance.\n",
    "\n",
    "Mean Squared Error and Mean Absolute Error are based on the squared and absolute error between the observed and predicted resale price. Thus, the closer these values are to 0, the more accurate the model.\n",
    "\n",
    "R-Squared determines the measure of variance between the dependent variable that is explained by the independent variables. It measures the goodness-of-fit for linear regression model from a range of 1 to 0, where 1 indicates a perfect model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5.2 Compare Models and Final Model <a name = \"eval2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models were tested with four different feature scalers as well as transforming remaining_lease from year to month to determine the best performing model based on the metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Model (remaining_lease(rl) year,sscaler)\n",
    "\n",
    "train MAE: 43368.04179190975\n",
    "\n",
    "train MSE: 3182629561.931875\n",
    "\n",
    "train R^2: 0.8654171556132857\n",
    "\n",
    "\n",
    "test MAE: 54038.97493917037\n",
    "\n",
    "test MSE: 5360853182.070648\n",
    "\n",
    "test R^2: 0.7734896068378345\n",
    "\n",
    "----------------------------\n",
    "\n",
    "Standard Scaler Model (rl month,sscaler) (Slight improvement over rl year) (Best model accuracy)\n",
    "\n",
    "train MAE: 43368.04169744031\n",
    "\n",
    "train MSE: 3182629559.822617\n",
    "\n",
    "train R^2: 0.8654171557024792\n",
    "\n",
    "test MAE: 54038.97421693898\n",
    "\n",
    "test MSE: 5360853041.811932\n",
    "\n",
    "test R^2: 0.7734896127641405\n",
    "\n",
    "----------------------------\n",
    "Min Max Scaler Model (rl month,minmaxscaler) (worse than sscaler)\n",
    "\n",
    "train MAE: 43363.725080087424\n",
    "\n",
    "train MSE: 3182213456.2019987\n",
    "\n",
    "train R^2: 0.8654347513439866\n",
    "\n",
    "test MAE: 70326.91432223978\n",
    "\n",
    "test MSE: 7938820136.060119\n",
    "\n",
    "test R^2: 0.6645636041149474\n",
    "\n",
    "------------------------------\n",
    "Robust Scaler Model (rl month,robustscaler) (worse than sscaler)\n",
    "\n",
    "train MAE: 83513.43817673266\n",
    "\n",
    "train MSE: 13089819835.92039\n",
    "\n",
    "train R^2: 0.4464749504310964\n",
    "\n",
    "test MAE: 82451.0570283069\n",
    "\n",
    "test MSE: 13463596906.583529\n",
    "\n",
    "test R^2: 0.43112700066349974\n",
    "\n",
    "------------------------------\n",
    "Max Absolute Scaler (rl month,maxabsscaler) (worse than sscaler)\n",
    "\n",
    "train MAE: 43363.72512272503\n",
    "\n",
    "train MSE: 3182213456.2019687\n",
    "\n",
    "train R^2: 0.865434751343988\n",
    "\n",
    "test MAE: 76895.07507788035\n",
    "\n",
    "test MSE: 9013418359.102718\n",
    "\n",
    "test R^2: 0.6191589534509785\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the results, we can see that the model using remaining_lease in month and scaled using Standard Scaler has the best overall performance among the models tested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Summary and Further Improvements<a name = \"sum\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.6.1 Summary of Findings <a name = \"sum1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the performance of the machine learning model built is satisfactory as it was able to achieve a test R-squared value of 0.7734 . Through data exploration and analysis, we were able to identify key trends as patterns that helped identify features that were useful for predicting the target variable based on the prediction problem statement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.6.2 Further Improvements <a name = \"sum2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the accuracy of the final model, there is definitely room for improvement as I believe the error present in the model can be further reduced to improve the performance.\n",
    "\n",
    "Some possible improvements that can be made are increasing the complexity of the model by adding new features derived from the original features. This will allow our model to train on more data which may potentially increase the models performance. Enriching the dataset with data and features from other sources, such as distance to nearest CC or MRT or last renovation date can also help to further refine the model.\n",
    "\n",
    "Lastly, model accuracy can be further optimized by testing other transformation methods such as outlier handling, normalizing, binning, and other numerical transformers such as log transformer, box-cox transformer, etc. To compare and find functions that best suit the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Unlisted\" Youtube Link to Video Presentation <a name = \"vid\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your link in this cell, you are allowed to comment it out\n",
    "# youtube link: \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
